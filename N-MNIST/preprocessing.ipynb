{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c0cbaa-e1f8-42de-bb65-e425966866de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import n2d2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tonic.datasets import NMNIST\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a60843-4209-4232-ab04-ce58e981f663",
   "metadata": {},
   "source": [
    "## Preprocessing: 3 channels (positive events, negative events, average timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f52ea5b-6865-4bd0-919b-d505db0688f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmnist_frames_3_channels(data_path=None, nr_samp=1):\n",
    "      import h5py\n",
    "      import os\n",
    "      import torchvision.transforms as transforms\n",
    "      import numpy as np\n",
    "      import random\n",
    "\n",
    "      length = []\n",
    "      samples = []\n",
    "      labels = []\n",
    "\n",
    "      def dvs_frames(data_path,item,filename):\n",
    "          with h5py.File(f\"{data_path}/{item}/{filename}\", \"r\") as f:\n",
    "\n",
    "                x = np.array(f[\"spikes\"][\"x\"])\n",
    "                y = np.array(f[\"spikes\"][\"y\"])\n",
    "                t = np.array(f[\"spikes\"][\"t\"])\n",
    "\n",
    "                fe = np.array(f[\"frame\"], dtype=\"float32\")\n",
    "                time_image = np.zeros([28,28])\n",
    "                total_events_matrix = fe[0] + fe[1]\n",
    "                for i in range(0,300):\n",
    "                  time_image[y[i]][x[i]] += t[i]/total_events_matrix[y[i]][x[i]]\n",
    "\n",
    "                frame = []\n",
    "\n",
    "                frame.append(fe[0]) # negative events\n",
    "                frame.append(fe[1]) # pozitive events\n",
    "                frame.append(np.array(time_image, dtype=\"float32\")) # timestamp average events\n",
    "                label = int(f[\"label\"][()].decode(\"utf-8\")) # retriving label for the frame\n",
    "                frame = np.array(frame)\n",
    "                # frame = np.transpose(np.array(frame), (1,2,0))\n",
    "\n",
    "\n",
    "                transform_1 = transforms.Compose(\n",
    "          [transforms.ToTensor(), transforms.Lambda(lambda x: x / fe[0].max() ), transforms.Normalize((0.5,), (0.5,))]\n",
    "      )\n",
    "                transform_2 = transforms.Compose(\n",
    "          [transforms.ToTensor(), transforms.Lambda(lambda x: x / fe[1].max() ), transforms.Normalize((0.5,), (0.5,))]\n",
    "      )\n",
    "                transform_3 = transforms.Compose(\n",
    "          [transforms.ToTensor(), transforms.Lambda(lambda x: x / frame[2].max() ), transforms.Normalize((0.5,), (0.5,))]\n",
    "      )\n",
    "                frame[0] = transform_1(frame[0])\n",
    "                frame[1] = transform_2(frame[1])\n",
    "                frame[2] = transform_3(frame[2])\n",
    "                return [frame, label]\n",
    "          return False\n",
    "      \n",
    "      print(\"Preprocessing of event data started ...\")\n",
    "      for item in os.listdir(data_path):\n",
    "        for i in range(0,nr_samp): # we can choose the number of frames to take for each sample\n",
    "          data = sorted(os.listdir(f\"{data_path}/{item}/\"))\n",
    "          if len(data)-2<0:\n",
    "            frame_to_take = random.randint(0,0)\n",
    "          else:\n",
    "            frame_to_take = random.randint(0,len(data)-2) # generating a random index (-2 because the last frame of time window was degenerated frame)\n",
    "          filename = sorted(os.listdir(f\"{data_path}/{item}/\"))[frame_to_take]\n",
    "          try:\n",
    "            data=dvs_frames(data_path,item,filename)\n",
    "            if data:\n",
    "                samples.append(data[0])\n",
    "                labels.append(data[1])\n",
    "            else:\n",
    "                print(\"Prolbem to open file: \", filename)\n",
    "          except Exception as e:\n",
    "            print(f\"Attention: {e}\")\n",
    "\n",
    "          if len(samples)%1000 == 0:\n",
    "                print(len(samples))\n",
    "\n",
    "      print(\"Data finished\")\n",
    "\n",
    "      return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd71c1f6-6a2e-4bb2-b74a-6fed8dc17915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of event data started ...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "Data finished\n",
      "Preprocessing of event data started ...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Data finished\n"
     ]
    }
   ],
   "source": [
    "train_data_spike_3_channels = preprocess_nmnist_frames_3_channels(\"dataset_train_spike/Train\", nr_samp=1)\n",
    "test_data_spike_3_channels = preprocess_nmnist_frames_3_channels(\"dataset_test_spike/Test\", nr_samp=1)\n",
    "\n",
    "data_3_channels = train_data_spike_3_channels[0] + test_data_spike_3_channels[0]\n",
    "labels_3_channels = train_data_spike_3_channels[1] + test_data_spike_3_channels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1ab660-dd4b-4c22-9a54-64d8dc17eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_3_channels.pkl', 'wb') as file:\n",
    "    pickle.dump(data_3_channels, file)\n",
    "with open('labels_3_channels.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_3_channels, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e827f-f973-4b64-8103-0444e0a92aec",
   "metadata": {},
   "source": [
    "## Preprocessing: 2 channels (positive events, negative events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb5e7b3-1f96-4767-b9d5-a5f2880ada48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmnist_frames_2_channels(data_path=None, nr_samp=1):\n",
    "      import h5py\n",
    "      import os\n",
    "      import torchvision.transforms as transforms\n",
    "      import numpy as np\n",
    "      import random\n",
    "\n",
    "      length = []\n",
    "      samples = []\n",
    "      labels = []\n",
    "\n",
    "      def dvs_frames(data_path,item,filename):\n",
    "          with h5py.File(f\"{data_path}/{item}/{filename}\", \"r\") as f:\n",
    "\n",
    "                x = np.array(f[\"spikes\"][\"x\"])\n",
    "                y = np.array(f[\"spikes\"][\"y\"])\n",
    "                t = np.array(f[\"spikes\"][\"t\"])\n",
    "\n",
    "                fe = np.array(f[\"frame\"], dtype=\"float32\")\n",
    "                time_image = np.zeros([28,28])\n",
    "                total_events_matrix = fe[0] + fe[1]\n",
    "                for i in range(0,300):\n",
    "                  time_image[y[i]][x[i]] += t[i]/total_events_matrix[y[i]][x[i]]\n",
    "\n",
    "                frame = []\n",
    "\n",
    "                frame.append(fe[0]) # negative events\n",
    "                frame.append(fe[1]) # pozitive events\n",
    "                #frame.append(np.array(time_image, dtype=\"float32\")) # timestamp average events\n",
    "                label = int(f[\"label\"][()].decode(\"utf-8\")) # retriving label for the frame\n",
    "                frame = np.array(frame)\n",
    "                # frame = np.transpose(np.array(frame), (1,2,0))\n",
    "\n",
    "\n",
    "                transform_1 = transforms.Compose(\n",
    "          [transforms.ToTensor(), transforms.Lambda(lambda x: x / fe[0].max() ), transforms.Normalize((0.5,), (0.5,))]\n",
    "      )\n",
    "                transform_2 = transforms.Compose(\n",
    "          [transforms.ToTensor(), transforms.Lambda(lambda x: x / fe[1].max() ), transforms.Normalize((0.5,), (0.5,))]\n",
    "      )\n",
    "                transform_3 = transforms.Compose(\n",
    "          [transforms.ToTensor(), transforms.Lambda(lambda x: x / frame[2].max() ), transforms.Normalize((0.5,), (0.5,))]\n",
    "      )\n",
    "                frame[0] = transform_1(frame[0])\n",
    "                frame[1] = transform_2(frame[1])\n",
    "                #frame[2] = transform_3(frame[2])\n",
    "                return [frame, label]\n",
    "          return False\n",
    "      \n",
    "      print(\"Preprocessing of event data started ...\")\n",
    "      for item in os.listdir(data_path):\n",
    "        for i in range(0,nr_samp): # we can choose the number of frames to take for each sample\n",
    "          data = sorted(os.listdir(f\"{data_path}/{item}/\"))\n",
    "          if len(data)-2<0:\n",
    "            frame_to_take = random.randint(0,0)\n",
    "          else:\n",
    "            frame_to_take = random.randint(0,len(data)-2) # generating a random index (-2 because the last frame of time window was degenerated frame)\n",
    "          filename = sorted(os.listdir(f\"{data_path}/{item}/\"))[frame_to_take]\n",
    "          try:\n",
    "            data=dvs_frames(data_path,item,filename)\n",
    "            if data:\n",
    "                samples.append(data[0])\n",
    "                labels.append(data[1])\n",
    "            else:\n",
    "                print(\"Prolbem to open file: \", filename)\n",
    "          except Exception as e:\n",
    "            print(f\"Attention: {e}\")\n",
    "                  \n",
    "        if len(samples)%1000 == 0:\n",
    "            print(len(samples))\n",
    "\n",
    "\n",
    "      print(\"Data finished\")\n",
    "\n",
    "\n",
    "      return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72013cf-5496-4ad0-bb74-b67d94e44dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of event data started ...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "Data finished\n",
      "Preprocessing of event data started ...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Data finished\n"
     ]
    }
   ],
   "source": [
    "train_data_spike_2_channels = preprocess_nmnist_frames_2_channels(\"dataset_train_spike/Train\", nr_samp=1)\n",
    "test_data_spike_2_channels = preprocess_nmnist_frames_2_channels(\"dataset_test_spike/Test\", nr_samp=1)\n",
    "\n",
    "data_2_channels = train_data_spike_2_channels[0] + test_data_spike_2_channels[0]\n",
    "labels_2_channels = train_data_spike_2_channels[1] + test_data_spike_2_channels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a12eee-a8f5-440c-9fb5-53498c3e8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_2_channels.pkl', 'wb') as file:\n",
    "    pickle.dump(data_2_channels, file)\n",
    "with open('labels_2_channels.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_2_channels, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5f92f-d03b-40a5-998b-5b41d833e036",
   "metadata": {},
   "source": [
    "## Preprocessing: Positive Events + Negative Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375ba868-eadc-42f7-86d9-3a565b09acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmnist_frames_sum(data_path=None, nr_samp=1):\n",
    "      import h5py\n",
    "      import os\n",
    "      import torchvision.transforms as transforms\n",
    "      import numpy as np\n",
    "      import random\n",
    "\n",
    "      length = []\n",
    "      samples = []\n",
    "      labels = []\n",
    "    \n",
    "      def frame_label(data_path, item, filename):\n",
    "            with h5py.File(f\"{data_path}/{item}/{filename}\", \"r\") as f:\n",
    "                frame = np.array(f[\"frame\"][0]+f[\"frame\"][1],dtype=\"float32\")\n",
    "                transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x / frame.max() ), transforms.Normalize((0.5,), (0.5,))])\n",
    "                frame = transform(frame) # transforming data of frames\n",
    "                label = int(f[\"label\"][()].decode(\"utf-8\")) # retriving label for the frame\n",
    "                return [frame, label]\n",
    "            return False\n",
    "\n",
    "      \n",
    "      print(\"Preprocessing of event data started ...\")\n",
    "      for item in os.listdir(data_path):\n",
    "        for i in range(0,nr_samp): # we can choose the number of frames to take for each sample\n",
    "          data = sorted(os.listdir(f\"{data_path}/{item}/\"))\n",
    "          if len(data)-2<0:\n",
    "            frame_to_take = random.randint(0,0)\n",
    "          else:\n",
    "            frame_to_take = random.randint(0,len(data)-2) # generating a random index (-2 because the last frame of time window was degenerated frame)\n",
    "            filename = sorted(os.listdir(f\"{data_path}/{item}/\"))[frame_to_take]\n",
    "          try:\n",
    "            data=frame_label(data_path,item,filename)\n",
    "            if data:\n",
    "                samples.append(data[0].numpy())\n",
    "                labels.append(data[1])\n",
    "            else:\n",
    "                print(\"Prolbem to open file: \", filename)\n",
    "          except Exception as e:\n",
    "                print(f\"Attention: {e}\")  \n",
    "              \n",
    "\n",
    "          if len(samples)%1000 == 0:\n",
    "                print(len(samples))\n",
    "\n",
    "      print(\"Data finished\")\n",
    "\n",
    "\n",
    "      return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482f014-5625-4209-a77d-8a3c0d437b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of event data started ...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "Attention: [Errno 2] Unable to synchronously open file (unable to open file: name = 'dataset_train_spike/Train/17665_53b41/4.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "train_data_spike_sum = preprocess_nmnist_frames_sum(\"dataset_train_spike/Train\", nr_samp=1)\n",
    "test_data_spike_sum = preprocess_nmnist_frames_sum(\"dataset_test_spike/Test\", nr_samp=1)\n",
    "\n",
    "data_sum = train_data_spike_sum[0] + test_data_spike_sum[0]\n",
    "labels_sum = train_data_spike_sum[1] + test_data_spike_sum[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d0101-e414-414b-b216-10279ee384b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_sum.pkl', 'wb') as file:\n",
    "    pickle.dump(data_sum, file)\n",
    "with open('labels_sum.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_sum, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e431095-e66e-48b9-ac83-e3016c69efca",
   "metadata": {},
   "source": [
    "## Preprocessing: Positive Events - Negative Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aafbd4-a092-4ee8-bca1-f1e6a6907075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmnist_frames_sub(data_path=None, nr_samp=1):\n",
    "      import h5py\n",
    "      import os\n",
    "      import torchvision.transforms as transforms\n",
    "      import numpy as np\n",
    "      import random\n",
    "\n",
    "      length = []\n",
    "      samples = []\n",
    "      labels = []\n",
    "    \n",
    "      def frame_label(data_path, item, filename):\n",
    "            with h5py.File(f\"{data_path}/{item}/{filename}\", \"r\") as f:\n",
    "                frame = np.array(f[\"frame\"][1]-f[\"frame\"][0],dtype=\"float32\")\n",
    "                transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x / frame.max() ), transforms.Normalize((0.5,), (0.5,))])\n",
    "                frame = transform(frame) # transforming data of frames\n",
    "                label = int(f[\"label\"][()].decode(\"utf-8\")) # retriving label for the frame\n",
    "                return [frame, label]\n",
    "            return False\n",
    "\n",
    "      \n",
    "      print(\"Preprocessing of event data started ...\")\n",
    "      for item in os.listdir(data_path):\n",
    "        for i in range(0,nr_samp): # we can choose the number of frames to take for each sample\n",
    "          data = sorted(os.listdir(f\"{data_path}/{item}/\"))\n",
    "          if len(data)-2<0:\n",
    "            frame_to_take = random.randint(0,0)\n",
    "          else:\n",
    "            frame_to_take = random.randint(0,len(data)-2) # generating a random index (-2 because the last frame of time window was degenerated frame)\n",
    "            filename = sorted(os.listdir(f\"{data_path}/{item}/\"))[frame_to_take]\n",
    "          try:\n",
    "            data=frame_label(data_path,item,filename)\n",
    "            if data:\n",
    "                samples.append(data[0].numpy())\n",
    "                labels.append(data[1])\n",
    "            else:\n",
    "                print(\"Prolbem to open file: \", filename)\n",
    "          except Exception as e:\n",
    "                print(f\"Attention: {e}\")  \n",
    "              \n",
    "\n",
    "          if len(samples)%1000 == 0:\n",
    "                print(len(samples))\n",
    "\n",
    "      print(\"Data finished\")\n",
    "\n",
    "\n",
    "      return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1a27d-8c71-41f5-9134-1c10be269e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spike_sub = preprocess_nmnist_frames_sub(\"dataset_train_spike/Train\", nr_samp=1)\n",
    "test_data_spike_sub = preprocess_nmnist_frames_sub(\"dataset_test_spike/Test\", nr_samp=1)\n",
    "\n",
    "data_sub = train_data_spike_sub[0] + test_data_spike_sub[0]\n",
    "labels_sub = train_data_spike_sub[1] + test_data_spike_sub[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc0c3e-4b9c-4e49-ac9e-f0bced613808",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_sub.pkl', 'wb') as file:\n",
    "    pickle.dump(data_sub, file)\n",
    "with open('labels_sub.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_sub, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6525a578-15d2-4d95-afd7-97767f0395f4",
   "metadata": {},
   "source": [
    "## Preprocessing: Only Positive Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ee3c2-3c67-4d35-80aa-e2d9d1741103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmnist_frames_positive(data_path=None, nr_samp=1):\n",
    "      import h5py\n",
    "      import os\n",
    "      import torchvision.transforms as transforms\n",
    "      import numpy as np\n",
    "      import random\n",
    "\n",
    "      length = []\n",
    "      samples = []\n",
    "      labels = []\n",
    "    \n",
    "      def frame_label(data_path, item, filename):\n",
    "            with h5py.File(f\"{data_path}/{item}/{filename}\", \"r\") as f:\n",
    "                frame = np.array(f[\"frame\"][1],dtype=\"float32\")\n",
    "                transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x / frame.max() ), transforms.Normalize((0.5,), (0.5,))])\n",
    "                frame = transform(frame) # transforming data of frames\n",
    "                label = int(f[\"label\"][()].decode(\"utf-8\")) # retriving label for the frame\n",
    "                return [frame, label]\n",
    "            return False\n",
    "\n",
    "      \n",
    "      print(\"Preprocessing of event data started ...\")\n",
    "      for item in os.listdir(data_path):\n",
    "        for i in range(0,nr_samp): # we can choose the number of frames to take for each sample\n",
    "          data = sorted(os.listdir(f\"{data_path}/{item}/\"))\n",
    "          if len(data)-2<0:\n",
    "            frame_to_take = random.randint(0,0)\n",
    "          else:\n",
    "            frame_to_take = random.randint(0,len(data)-2) # generating a random index (-2 because the last frame of time window was degenerated frame)\n",
    "            filename = sorted(os.listdir(f\"{data_path}/{item}/\"))[frame_to_take]\n",
    "          try:\n",
    "            data=frame_label(data_path,item,filename)\n",
    "            if data:\n",
    "                samples.append(data[0].numpy())\n",
    "                labels.append(data[1])\n",
    "            else:\n",
    "                print(\"Prolbem to open file: \", filename)\n",
    "          except Exception as e:\n",
    "                print(f\"Attention: {e}\")  \n",
    "              \n",
    "\n",
    "          if len(samples)%1000 == 0:\n",
    "                print(len(samples))\n",
    "\n",
    "      print(\"Data finished\")\n",
    "\n",
    "\n",
    "      return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07c15a-aa20-40f5-a4f9-05bba1124730",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spike_positive = preprocess_nmnist_frames_positive(\"dataset_train_spike/Train\", nr_samp=1)\n",
    "test_data_spike_positive = preprocess_nmnist_frames_positive(\"dataset_test_spike/Test\", nr_samp=1)\n",
    "\n",
    "data_positive = train_data_spike_positive[0] + test_data_spike_positive[0]\n",
    "labels_positive = train_data_spike_positive[1] + test_data_spike_positive[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322aced-a980-41c7-b777-ec1fe699d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_positive.pkl', 'wb') as file:\n",
    "    pickle.dump(data_positive, file)\n",
    "with open('labels_positive.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_positive, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eeb865-ce20-4bea-9313-284767d3e172",
   "metadata": {},
   "source": [
    "## Preprocessing: Only Negative Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74eabb-39ee-4013-8ede-a90ab5cccbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmnist_frames_negative(data_path=None, nr_samp=1):\n",
    "      import h5py\n",
    "      import os\n",
    "      import torchvision.transforms as transforms\n",
    "      import numpy as np\n",
    "      import random\n",
    "\n",
    "      length = []\n",
    "      samples = []\n",
    "      labels = []\n",
    "    \n",
    "      def frame_label(data_path, item, filename):\n",
    "            with h5py.File(f\"{data_path}/{item}/{filename}\", \"r\") as f:\n",
    "                frame = np.array(f[\"frame\"][0],dtype=\"float32\")\n",
    "                transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x / frame.max() ), transforms.Normalize((0.5,), (0.5,))])\n",
    "                frame = transform(frame) # transforming data of frames\n",
    "                label = int(f[\"label\"][()].decode(\"utf-8\")) # retriving label for the frame\n",
    "                return [frame, label]\n",
    "            return False\n",
    "\n",
    "      \n",
    "      print(\"Preprocessing of event data started ...\")\n",
    "      for item in os.listdir(data_path):\n",
    "        for i in range(0,nr_samp): # we can choose the number of frames to take for each sample\n",
    "          data = sorted(os.listdir(f\"{data_path}/{item}/\"))\n",
    "          if len(data)-2<0:\n",
    "            frame_to_take = random.randint(0,0)\n",
    "          else:\n",
    "            frame_to_take = random.randint(0,len(data)-2) # generating a random index (-2 because the last frame of time window was degenerated frame)\n",
    "            filename = sorted(os.listdir(f\"{data_path}/{item}/\"))[frame_to_take]\n",
    "          try:\n",
    "            data=frame_label(data_path,item,filename)\n",
    "            if data:\n",
    "                samples.append(data[0].numpy())\n",
    "                labels.append(data[1])\n",
    "            else:\n",
    "                print(\"Prolbem to open file: \", filename)\n",
    "          except Exception as e:\n",
    "                print(f\"Attention: {e}\")  \n",
    "              \n",
    "\n",
    "          if len(samples)%1000 == 0:\n",
    "                print(len(samples))\n",
    "\n",
    "      print(\"Data finished\")\n",
    "\n",
    "\n",
    "      return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe4e2d-5508-46bc-86a4-4bf482b3ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spike_negative = preprocess_nmnist_frames_negative(\"dataset_train_spike/Train\", nr_samp=1)\n",
    "test_data_spike_negative = preprocess_nmnist_frames_negative(\"dataset_test_spike/Test\", nr_samp=1)\n",
    "\n",
    "data_negative = train_data_spike_negative[0] + test_data_spike_negative[0]\n",
    "labels_negative = train_data_spike_negative[1] + test_data_spike_negative[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738dbb0-e951-43c6-bd2a-23c773d22325",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_negative.pkl', 'wb') as file:\n",
    "    pickle.dump(data_negative, file)\n",
    "with open('labels_negative.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_negative, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
