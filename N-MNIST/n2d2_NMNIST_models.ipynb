{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c0cbaa-e1f8-42de-bb65-e425966866de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import n2d2\n",
    "from n2d2.cells.nn import Fc, Conv, Pool2d\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c35364-9627-4b92-a0c3-7075208fb269",
   "metadata": {},
   "source": [
    "## N-MNIST - 2-Channel Representation - Final Table\n",
    "\n",
    "# 1st Architecure\n",
    "| Quantization Level | Accuracy | Training Time | Inference Time |\n",
    "| ------------------- | -------- | ------------- | -------------- |\n",
    "| No quantization     | 95.43%      | 55 min 42 sec    | 5.037912 sec   |\n",
    "| 8 bits              | 93.09%     | 58 min 35 sec  | 5.391217 sec    |\n",
    "| 4 bits              | 92.65%      | 60 min 1 sec    |5.432344 sec    |\n",
    "| 2 bits              | 88.66%    | 59 min 28 sec    | 5.53196 sec   |\n",
    "| 1 bit               | 77.84%     | 59 min 5 sec     | 5.411371 sec    |\n",
    "\n",
    "# 2st Architecure (Deeper)\n",
    "| Quantization Level | Accuracy | Training Time | Inference Time |\n",
    "| ------------------- | -------- | ------------- | -------------- |\n",
    "| No quantization     | 95.72%     | 76 min 38 sec    | 9.994629 sec   |\n",
    "| 8 bits              | 95.12%   | 78 min 49 sec   | 10.218431 sec    |\n",
    "| 4 bits              | 94.79%   | 79 min 9 sec     | 13.404536 sec     |\n",
    "| 2 bits              | 91.96%     | 77 min 42 sec       | 11.775391 sec    |\n",
    "| 1 bit               | 89.95%    | 75 min 17 sec      | 12.245561 sec   |\n",
    "\n",
    "# 3rd Architecure (Deeper)\n",
    "| Quantization Level | Accuracy | Training Time | Inference Time |\n",
    "| ------------------- | -------- | ------------- | -------------- |\n",
    "| No quantization     | 95.44%     | 96 min 22 sec   | 13.336893 sec   |\n",
    "| 8 bits              | 96.57%   | 104 min 28 sec   | 13.512858 sec   |\n",
    "| 4 bits              | 96.01%    | 105 min 26 sec    | 13.937486 sec     |\n",
    "| 2 bits              | 93.41%     | 106 min 0 sec      | 15.273108 sec    |\n",
    "| 1 bit               | 93.10%    | 105 min 34 sec     | 15.46094 sec   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86c596f-d458-4f38-abd5-3a13f6e812b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_conf = n2d2.ConfigSection(\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "\n",
    "def conv_conf():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "    \n",
    "def fc_conf1():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "def fc_conf2():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Linear(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "    \n",
    "# Definition of layers for quantization\n",
    "\n",
    "def conv_quantization_conf(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def fc_quantization_conf1(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )\n",
    "def fc_quantization_conf2(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Linear(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc8fb1-8fc4-4dd2-bc07-df860c3be44f",
   "metadata": {},
   "source": [
    "## N-MNIST : 2 channels (positive events, negative events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b879fc01-1ff5-44ca-a456-7f8f9f9d15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_final/data_2_channels.pkl', 'rb') as file:\n",
    "    data_2_channels = pickle.load(file)\n",
    "with open('data_final/labels_2_channels.pkl', 'rb') as file:\n",
    "    labels_2_channels = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd8ad2-3e5f-49a7-8958-9c6443f1ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = n2d2.database.Numpy(random_partitioning=False)\n",
    "\n",
    "db.load(data_2_channels, labels_2_channels)\n",
    "db.partition_stimuli(5/7, 1/7, 1/7) # training: 50k, validation: 10k, test: 10k\n",
    "\n",
    "print(\"\\n### Create Provider ###\")\n",
    "batch_size = 64\n",
    "provider = n2d2.provider.DataProvider(db, [32, 32, 2], batch_size=batch_size)\n",
    "provider.add_transformation(n2d2.transform.Rescale(width=32, height=32))\n",
    "print(provider)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7843e6-0d6f-4749-8234-d4a447537e9e",
   "metadata": {},
   "source": [
    "# 1st architecture\n",
    "## Model without quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af09a1e-a723-469b-a31f-0d4c3f446f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Loading Model (without quantization) ###\")\n",
    "model_2_channels = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_conf()),\n",
    "    Fc(120, 84, **fc_conf1()),\n",
    "    Fc(84, 10, **fc_conf2()),\n",
    "])\n",
    "print(model_2_channels)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0ed69-2d29-4e43-be58-d1199c643e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "        \n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220da472-ebbe-496e-b129-24716a903ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels/Conv_0.syntxt\n",
      "Import ./model_2_channels/Conv_1.syntxt\n",
      "Import ./model_2_channels/Conv_2.syntxt\n",
      "Import ./model_2_channels/Fc_0.syntxt\n",
      "Import ./model_2_channels/Fc_1.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.43%\n",
      "Inference time: 0 min 4.477286 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.43%\n",
      "Inference time: 0 min 4.442044 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.43%\n",
      "Inference time: 0 min 4.791932 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.43%\n",
      "Inference time: 0 min 4.910183 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.43%\n",
      "Inference time: 0 min 5.037912 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 4.731871 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels.import_free_parameters(\"./model_2_channels\", ignore_not_exists=True)\n",
    "\n",
    "target = n2d2.target.Score(provider)\n",
    "provider.set_partition('Test')\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4c858-8167-49a8-a319-f269bda293df",
   "metadata": {},
   "source": [
    "## N-MNIST - 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4b603-bddf-484e-b3ef-d69ab1684799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (8 bit quantization) ###\")\n",
    "model_2_channels_quant_8bit = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(8)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(8)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(8)),\n",
    "])\n",
    "print(model_2_channels_quant_8bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb6b21-4b99-4691-83c4-6b218f991f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_8bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_8bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13984e3a-3468-428d-85d9-f1f13427f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_8bit/Conv_3.syntxt\n",
      "Import ./model_2_channels_quant_8bit/Conv_4.syntxt\n",
      "Import ./model_2_channels_quant_8bit/Conv_5.syntxt\n",
      "Import ./model_2_channels_quant_8bit/Fc_2.syntxt\n",
      "Import ./model_2_channels_quant_8bit/Fc_3.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.09%\n",
      "Inference time: 0 min 5.38137 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.09%\n",
      "Inference time: 0 min 5.50287 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.09%\n",
      "Inference time: 0 min 6.615218 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.09%\n",
      "Inference time: 0 min 5.360242 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.09%\n",
      "Inference time: 0 min 5.391217 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 5.650183 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_8bit.import_free_parameters(\"./model_2_channels_quant_8bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_8bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_8bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_8bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be79a6-3711-41dc-afd5-3faac5b63f36",
   "metadata": {},
   "source": [
    "## N-MNIST - 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032012a-d090-4f45-a2c0-7267a46f25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (4 bit quantization) ###\")\n",
    "model_2_channels_quant_4bit = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(4)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(4)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(4)),\n",
    "])\n",
    "print(model_2_channels_quant_4bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d406b09-0398-4cf2-b8d2-16305aca0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_4bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_4bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ef8016-f72b-4b80-ae30-ae0a46723eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_4bit/Conv_6.syntxt\n",
      "Import ./model_2_channels_quant_4bit/Conv_7.syntxt\n",
      "Import ./model_2_channels_quant_4bit/Conv_8.syntxt\n",
      "Import ./model_2_channels_quant_4bit/Fc_4.syntxt\n",
      "Import ./model_2_channels_quant_4bit/Fc_5.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 92.65%\n",
      "Inference time: 0 min 5.580417 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 92.65%\n",
      "Inference time: 0 min 5.351107 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 92.65%\n",
      "Inference time: 0 min 5.451665 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 92.65%\n",
      "Inference time: 0 min 5.464402 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 92.65%\n",
      "Inference time: 0 min 5.432344 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 5.455987 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_4bit.import_free_parameters(\"./model_2_channels_quant_4bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_4bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_4bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_4bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940dd97-8d88-4c01-983d-2b76a5032b89",
   "metadata": {},
   "source": [
    "## N-MNIST - 2 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc5eaf-2fa6-4225-8700-e27fae4f9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (2 bit quantization) ###\")\n",
    "model_2_channels_quant_2bit = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(2)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(2)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(2)),\n",
    "])\n",
    "print(model_2_channels_quant_2bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88509629-3594-4104-9cb2-185680debaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_2bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_2bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34825a21-6376-44e2-8f2f-6ec45ab7117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_2bit/Conv_9.syntxt\n",
      "Import ./model_2_channels_quant_2bit/Conv_10.syntxt\n",
      "Import ./model_2_channels_quant_2bit/Conv_11.syntxt\n",
      "Import ./model_2_channels_quant_2bit/Fc_6.syntxt\n",
      "Import ./model_2_channels_quant_2bit/Fc_7.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 88.66%\n",
      "Inference time: 0 min 6.055706 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 88.66%\n",
      "Inference time: 0 min 5.190175 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 88.66%\n",
      "Inference time: 0 min 5.147417 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 88.66%\n",
      "Inference time: 0 min 5.353125 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 88.66%\n",
      "Inference time: 0 min 5.53196 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 5.455677 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_2bit.import_free_parameters(\"./model_2_channels_quant_2bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_2bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_2bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_2bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637c433-f946-4507-a35f-5949a17a20a6",
   "metadata": {},
   "source": [
    "## N-MNIST -  1 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cb039-1424-4a6d-8207-792ceff93159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 bit quantization\n",
    "\n",
    "print(\"\\n### Loading Model (1 bit quantization) ###\")\n",
    "model_2_channels_quant_1bit = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(1)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(1)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(1)),\n",
    "])\n",
    "print(model_2_channels_quant_1bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad7982-43d1-4421-ad8e-c55ffe1e0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_1bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_1bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595e0569-ebf7-455d-b5b2-5b0bb5d37913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_1bit/Conv_12.syntxt\n",
      "Import ./model_2_channels_quant_1bit/Conv_13.syntxt\n",
      "Import ./model_2_channels_quant_1bit/Conv_14.syntxt\n",
      "Import ./model_2_channels_quant_1bit/Fc_8.syntxt\n",
      "Import ./model_2_channels_quant_1bit/Fc_9.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 77.84%\n",
      "Inference time: 0 min 5.65261 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 77.84%\n",
      "Inference time: 0 min 5.400117 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 77.84%\n",
      "Inference time: 0 min 5.405207 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 77.84%\n",
      "Inference time: 0 min 5.358212 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 77.84%\n",
      "Inference time: 0 min 5.411371 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 5.445503 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_1bit.import_free_parameters(\"./model_2_channels_quant_1bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_1bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_1bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_1bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e6d19-8fc8-4b61-8573-15908da1732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in model_2_channels_quant_1bit.get_cells().values():\n",
    "     try:\n",
    "        weights = cell.get_weights()\n",
    "        print(weights)\n",
    "     except AttributeError as e:\n",
    "        print(f\"Attention: {cell} Error: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3d55e-36a1-4f04-9ac5-5215462ab1a8",
   "metadata": {},
   "source": [
    "# 2nd architecture\n",
    "## Model no quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa1aed-a223-4df6-a29d-232338c53d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Loading Model (without quantization) ###\")\n",
    "model_2_channels_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_conf()),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_conf()),\n",
    "    Conv(24, 120, [5, 5], **conv_conf()), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_conf1()),\n",
    "    Fc(84, 10, **fc_conf2()),\n",
    "])\n",
    "print(model_2_channels_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e03ddf-3b2a-4d43-9866-2e2103d532dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "        \n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b03f5a-f75f-4a4f-9468-465c0b7e909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_deeper_2nd/Conv_0.syntxt\n",
      "Import ./model_2_channels_deeper_2nd/Conv_1.syntxt\n",
      "Import ./model_2_channels_deeper_2nd/Conv_2.syntxt\n",
      "Import ./model_2_channels_deeper_2nd/Conv_3.syntxt\n",
      "Import ./model_2_channels_deeper_2nd/Fc_0.syntxt\n",
      "Import ./model_2_channels_deeper_2nd/Fc_1.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.72%\n",
      "Inference time: 0 min 8.419773 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.72%\n",
      "Inference time: 0 min 9.233911 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.72%\n",
      "Inference time: 0 min 12.309228 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.72%\n",
      "Inference time: 0 min 9.673053 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.72%\n",
      "Inference time: 0 min 9.994629 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 9.926119 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_deeper_2nd.import_free_parameters(\"./model_2_channels_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "target = n2d2.target.Score(provider)\n",
    "provider.set_partition('Test')\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f5c5a-d703-45e4-b5d6-b2b2569533df",
   "metadata": {},
   "source": [
    "## N-MNIST - 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63caa4-2cbb-4f45-a820-461e2d192ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (8 bit quantization) ###\")\n",
    "model_2_channels_quant_8bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(8)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(8)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(8)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(8)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(8)),\n",
    "])\n",
    "print(model_2_channels_quant_8bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c729a9-1d2a-48b5-a9a8-403e1e2cbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_8bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_8bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_8bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_8bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e3a82d-4186-4f8b-9ab6-b4632e17d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_8bit_deeper_2nd/Conv_4.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_2nd/Conv_5.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_2nd/Conv_6.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_2nd/Conv_7.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_2nd/Fc_2.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_2nd/Fc_3.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.12%\n",
      "Inference time: 0 min 10.228018 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.12%\n",
      "Inference time: 0 min 10.412936 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.12%\n",
      "Inference time: 0 min 10.298758 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.12%\n",
      "Inference time: 0 min 10.269832 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.12%\n",
      "Inference time: 0 min 10.218431 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 10.285595 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_8bit_deeper_2nd.import_free_parameters(\"./model_2_channels_quant_8bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_8bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_8bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_8bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_8bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbdf1fa-3e76-4a35-92fe-fd098d4e6138",
   "metadata": {},
   "source": [
    "## N-MNIST - 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1bf74-0ec9-4cf1-9db3-7841b3eeac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (4 bit quantization) ###\")\n",
    "model_2_channels_quant_4bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(4)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(4)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(4)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(4)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(4)),\n",
    "])\n",
    "print(model_2_channels_quant_4bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9e904-aae6-409e-b980-09084eb55a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_4bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_4bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_4bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_4bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e8cb05-d5d3-498d-a564-84080dfd3450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_4bit_deeper_2nd/Conv_8.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_2nd/Conv_9.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_2nd/Conv_10.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_2nd/Conv_11.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_2nd/Fc_4.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_2nd/Fc_5.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 94.79%\n",
      "Inference time: 0 min 10.418203 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 94.79%\n",
      "Inference time: 0 min 10.505937 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 94.79%\n",
      "Inference time: 0 min 10.593153 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 94.79%\n",
      "Inference time: 0 min 10.650608 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 94.79%\n",
      "Inference time: 0 min 13.404536 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 11.114487 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_4bit_deeper_2nd.import_free_parameters(\"./model_2_channels_quant_4bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_4bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_4bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_4bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_4bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc499c75-c0d3-4871-a7da-4773c7f75d81",
   "metadata": {},
   "source": [
    "## N-MNIST - 2 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fdaf7-5824-4e3c-bd51-9034ae965be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (2 bit quantization) ###\")\n",
    "model_2_channels_quant_2bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(2)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(2)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(2)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(2)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(2)),\n",
    "])\n",
    "print(model_2_channels_quant_2bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8883ccf-9316-44ec-ae8e-18c3200dad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_2bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_2bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_2bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_2bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f17af8fa-615a-41bd-895a-6f78245c994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_2bit_deeper_2nd/Conv_12.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_2nd/Conv_13.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_2nd/Conv_14.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_2nd/Conv_15.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_2nd/Fc_6.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_2nd/Fc_7.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 91.96%\n",
      "Inference time: 0 min 12.769133 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 91.96%\n",
      "Inference time: 0 min 11.347889 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 91.96%\n",
      "Inference time: 0 min 11.520325 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 91.96%\n",
      "Inference time: 0 min 11.538457 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 91.96%\n",
      "Inference time: 0 min 11.775391 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 11.790239 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_2bit_deeper_2nd.import_free_parameters(\"./model_2_channels_quant_2bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_2bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_2bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_2bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_2bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831cc83d-6143-4eaf-b403-a7792227f1b5",
   "metadata": {},
   "source": [
    "## N-MNIST -  1 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713144b-92a2-4072-8f22-77d81786eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 bit quantization\n",
    "\n",
    "print(\"\\n### Loading Model (1 bit quantization) ###\")\n",
    "model_2_channels_quant_1bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(1)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(1)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(1)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(1)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(1)),\n",
    "])\n",
    "print(model_2_channels_quant_1bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb0096-8872-4057-b62c-c99e85b9e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_1bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_1bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_1bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_1bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b26d6f69-8b3c-43dd-b2f5-b5494f182624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_1bit_deeper_2nd/Conv_16.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_2nd/Conv_17.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_2nd/Conv_18.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_2nd/Conv_19.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_2nd/Fc_8.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_2nd/Fc_9.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 89.95%\n",
      "Inference time: 0 min 11.888951 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 89.95%\n",
      "Inference time: 0 min 11.934367 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 89.95%\n",
      "Inference time: 0 min 12.12237 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 89.95%\n",
      "Inference time: 0 min 12.042581 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 89.95%\n",
      "Inference time: 0 min 12.245561 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 12.046766 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_1bit_deeper_2nd.import_free_parameters(\"./model_2_channels_quant_1bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_1bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_1bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_1bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_1bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72591c47-dd4b-471a-96c2-7124f50addb9",
   "metadata": {},
   "source": [
    "# 3rd architecture\n",
    "## Model no quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d61d21-2505-4f47-b1c0-2b0a1b24f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Loading Model (without quantization) ###\")\n",
    "model_2_channels_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_conf()),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_conf()),\n",
    "    Conv(32, 150, [5, 5], **conv_conf()), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_conf1()), # New Fc Layer\n",
    "    Fc(120, 84, **fc_conf1()),\n",
    "    Fc(84, 10, **fc_conf2()),\n",
    "])\n",
    "print(model_2_channels_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06127c69-176a-4410-8449-4185352bd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "        \n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d77a8e-42da-4e93-9421-e6e3deeab11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_deeper_3rd/Conv_0.syntxt\n",
      "Import ./model_2_channels_deeper_3rd/Conv_1.syntxt\n",
      "Import ./model_2_channels_deeper_3rd/Conv_2.syntxt\n",
      "Import ./model_2_channels_deeper_3rd/Conv_3.syntxt\n",
      "Import ./model_2_channels_deeper_3rd/Fc_0.syntxt\n",
      "Import ./model_2_channels_deeper_3rd/Fc_1.syntxt\n",
      "Import ./model_2_channels_deeper_3rd/Fc_2.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.44%\n",
      "Inference time: 0 min 10.576526 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.44%\n",
      "Inference time: 0 min 13.292106 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.44%\n",
      "Inference time: 0 min 12.498887 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.44%\n",
      "Inference time: 0 min 12.554495 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 95.44%\n",
      "Inference time: 0 min 13.336893 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 12.451781 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_deeper_3rd.import_free_parameters(\"./model_2_channels_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "target = n2d2.target.Score(provider)\n",
    "provider.set_partition('Test')\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98920027-a209-4aa8-8f95-3d2df909ea3c",
   "metadata": {},
   "source": [
    "## N-MNIST - 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78328f-3a62-4e1b-b61b-603fee320a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (8 bit quantization) ###\")\n",
    "model_2_channels_quant_8bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(8)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(8)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(8)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(8)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(8)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(8)),\n",
    "])\n",
    "print(model_2_channels_quant_8bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b99e2-96af-4a70-b8fc-dc668c025003",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_8bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_8bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_8bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_8bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871835c8-0157-4773-ad2e-aa0459e875a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_8bit_deeper_3rd/Conv_4.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_3rd/Conv_5.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_3rd/Conv_6.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_3rd/Conv_7.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_3rd/Fc_3.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_3rd/Fc_4.syntxt\n",
      "Import ./model_2_channels_quant_8bit_deeper_3rd/Fc_5.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.57%\n",
      "Inference time: 0 min 13.364369 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.57%\n",
      "Inference time: 0 min 13.788347 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.57%\n",
      "Inference time: 0 min 13.423094 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.57%\n",
      "Inference time: 0 min 13.547475 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.57%\n",
      "Inference time: 0 min 13.512858 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 13.527229 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_8bit_deeper_3rd.import_free_parameters(\"./model_2_channels_quant_8bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_8bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_8bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_8bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_8bit_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe186c-ef10-474c-b77b-640b440c4519",
   "metadata": {},
   "source": [
    "## N-MNIST - 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614e448-dde9-49a4-8d17-af51921ddd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (4 bit quantization) ###\")\n",
    "model_2_channels_quant_4bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(4)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(4)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(4)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(4)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(4)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(4)),\n",
    "])\n",
    "print(model_2_channels_quant_4bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3dff8-4bd9-4862-9489-1138f1643667",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_4bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_4bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_4bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_4bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1de9e2c-7868-4ffc-ac3d-afcfc2e136f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_4bit_deeper_3rd/Conv_8.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_3rd/Conv_9.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_3rd/Conv_10.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_3rd/Conv_11.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_3rd/Fc_6.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_3rd/Fc_7.syntxt\n",
      "Import ./model_2_channels_quant_4bit_deeper_3rd/Fc_8.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.01%\n",
      "Inference time: 0 min 13.651471 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.01%\n",
      "Inference time: 0 min 13.594161 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.01%\n",
      "Inference time: 0 min 13.582885 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.01%\n",
      "Inference time: 0 min 13.796174 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 96.01%\n",
      "Inference time: 0 min 13.937486 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 13.712435 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_4bit_deeper_3rd.import_free_parameters(\"./model_2_channels_quant_4bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_4bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_4bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_4bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_4bit_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b646193-a1fd-4028-850a-6842944dba7f",
   "metadata": {},
   "source": [
    "## N-MNIST - 2 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d05c2-27b0-49cb-99bc-37d527f93bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (2 bit quantization) ###\")\n",
    "model_2_channels_quant_2bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(2)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(2)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(2)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(2)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(2)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(2)),\n",
    "])\n",
    "print(model_2_channels_quant_2bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1dc48-aeed-4986-a8de-ac450516a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_2bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_2bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_2bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_2bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e705900a-bab6-45a5-8a43-6dd65018b996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_2bit_deeper_3rd/Conv_12.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_3rd/Conv_13.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_3rd/Conv_14.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_3rd/Conv_15.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_3rd/Fc_9.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_3rd/Fc_10.syntxt\n",
      "Import ./model_2_channels_quant_2bit_deeper_3rd/Fc_11.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.41%\n",
      "Inference time: 0 min 14.576361 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.41%\n",
      "Inference time: 0 min 14.809438 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.41%\n",
      "Inference time: 0 min 15.00802 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.41%\n",
      "Inference time: 0 min 15.201233 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.41%\n",
      "Inference time: 0 min 15.273108 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 14.973632 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_2bit_deeper_3rd.import_free_parameters(\"./model_2_channels_quant_2bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_2bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_2bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_2bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_2bit_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a3981-2c40-4dd2-ab6f-9e3d1f427435",
   "metadata": {},
   "source": [
    "## N-MNIST -  1 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39144f-bb8e-4797-8f3a-490d8cf59326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 bit quantization\n",
    "\n",
    "print(\"\\n### Loading Model (1 bit quantization) ###\")\n",
    "model_2_channels_quant_1bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(2, 6, kernel_dims=[5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(1)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(1)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(1)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(1)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(1)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(1)),\n",
    "])\n",
    "print(model_2_channels_quant_1bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6b3f4-7fc8-467a-b543-d1ad11c6cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_2_channels_quant_1bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_2_channels_quant_1bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_2_channels_quant_1bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_1bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383bd912-addd-4c01-8864-6bf6808b1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_2_channels_quant_1bit_deeper_3rd/Conv_16.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_3rd/Conv_17.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_3rd/Conv_18.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_3rd/Conv_19.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_3rd/Fc_12.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_3rd/Fc_13.syntxt\n",
      "Import ./model_2_channels_quant_1bit_deeper_3rd/Fc_14.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.10%\n",
      "Inference time: 0 min 15.258002 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.10%\n",
      "Inference time: 0 min 15.249848 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.10%\n",
      "Inference time: 0 min 15.31612 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.10%\n",
      "Inference time: 0 min 15.30257 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 93.10%\n",
      "Inference time: 0 min 15.46094 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 15.317496 sec\n"
     ]
    }
   ],
   "source": [
    "model_2_channels_quant_1bit_deeper_3rd.import_free_parameters(\"./model_2_channels_quant_1bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_2_channels_quant_1bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_2_channels_quant_1bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_2_channels_quant_1bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_2_channels_quant_1bit_deeper_3rd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
