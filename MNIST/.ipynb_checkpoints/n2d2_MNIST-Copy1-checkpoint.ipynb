{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c0cbaa-e1f8-42de-bb65-e425966866de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import n2d2\n",
    "from n2d2.cells.nn import Fc, Conv, Pool2d\n",
    "import math\n",
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddbd15c-95e9-422a-b8c6-7734edcd2714",
   "metadata": {},
   "source": [
    "## MNIST - Final Table\n",
    "\n",
    "| Quantization Level | Accuracy | Training Time | Inference Time |\n",
    "| ------------------- | -------- | ------------- | -------------- |\n",
    "| No quantization     | 99.03%    | 40 min 30 sec    | 11.315785 sec     |\n",
    "| 8 bits              | 98.72%      | 43 min 55 sec   | 13.135024 sec     |\n",
    "| 4 bits              | 98.70%     | 45 min 1 sec    | 12.202406 sec    |\n",
    "| 2 bits              | 97.87%     | 46 min 59 sec    | 12.498027 sec    |\n",
    "| 1 bit               | 97.69%      | 47 min 6 sec    | 12.082054 sec    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87761499-c633-4244-9b95-69577d3ba3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and processing MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46eeed77-fc3c-4d0c-94c7-e608985e6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for item in train_dataset:\n",
    "    image, label = item\n",
    "    data.append(image.numpy())\n",
    "    labels.append(label)\n",
    "\n",
    "for item in test_dataset:\n",
    "    image, label = item\n",
    "    data.append(image.numpy())\n",
    "    labels.append(label)\n",
    "\n",
    "db = n2d2.database.Numpy(random_partitioning=False)\n",
    "db.load(data, labels)\n",
    "db.partition_stimuli(5/7, 1/7, 1/7) # training: 50k, validation: 10k, test: 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8596af0-1d09-4b35-8289-4d684f66a662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Create Provider ###\n",
      "'DataProvider_0' DataProvider(database=Numpy(composite_label=Auto, data_file_label=True, default_label=, multi_channel_match=, multi_channel_replace=, rois_margin=0, random_partitioning=False, target_data_path=), size=[32, 32, 1], batch_size=64)[Transformations=Rescale(width=32, height=32 | keep_aspect_ratio=False, resize_to_fit=True)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n### Create Provider ###\")\n",
    "batch_size = 64\n",
    "provider = n2d2.provider.DataProvider(db, [32, 32, 1], batch_size=batch_size)\n",
    "provider.add_transformation(n2d2.transform.Rescale(width=32, height=32))\n",
    "print(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e86295-43eb-4997-b0e0-b12511cc6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_conf = n2d2.ConfigSection(\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "\n",
    "def conv_conf():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "    \n",
    "def fc_conf1():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "def fc_conf2():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Linear(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "    \n",
    "# Definition of layers for quantization\n",
    "\n",
    "def conv_quantization_conf(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def fc_quantization_conf1(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )\n",
    "def fc_quantization_conf2(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Linear(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcc8a0-1f8d-4c4f-ac93-46d95eb3b5ad",
   "metadata": {},
   "source": [
    "## MNIST - No Quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bc7acd-89e5-42d7-bc45-974ab185f205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Loading Model (without quantization) ###\n",
      "'Sequence_0' Sequence(\n",
      "\t(0): 'Conv_0' Conv(Frame<float>)(nb_inputs=1, nb_outputs=6, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe30ecb9270>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=None)\n",
      "\t(1): 'Pool2d_0' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(2): 'Conv_1' Conv(Frame<float>)(nb_inputs=6, nb_outputs=16, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3106164b0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=None)\n",
      "\t(3): 'Pool2d_1' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(4): 'Conv_2' Conv(Frame<float>)(nb_inputs=16, nb_outputs=120, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe30efcaf30>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=None)\n",
      "\t(5): 'Fc_0' Fc(Frame<float>)(nb_inputs=120, nb_outputs=84 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe308361270>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=None)\n",
      "\t(6): 'Fc_1' Fc(Frame<float>)(nb_inputs=84, nb_outputs=10 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Linear(clipping=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3083619b0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n### Loading Model (without quantization) ###\")\n",
    "model_no_quantization = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_conf()),\n",
    "    Fc(120, 84, **fc_conf1()),\n",
    "    Fc(84, 10, **fc_conf2()),\n",
    "])\n",
    "print(model_no_quantization)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99260150-64e5-4b98-9952-79feb20949a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training ###\n",
      "Start time Training: 2023-12-03 18:54:24.425078\n",
      "\n",
      "# Train Epoch: 0 #\n",
      "Example: 49984, loss: 0.063\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.51%\n",
      "# Train Epoch: 1 #\n",
      "Example: 49984, loss: 0.006\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.26%\n",
      "# Train Epoch: 2 #\n",
      "Example: 49984, loss: 0.003\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.64%\n",
      "# Train Epoch: 3 #\n",
      "Example: 49984, loss: 0.001\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.84%\n",
      "# Train Epoch: 4 #\n",
      "Example: 49984, loss: 0.017\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.00%\n",
      "# Train Epoch: 5 #\n",
      "Example: 49984, loss: 0.002\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.08%\n",
      "# Train Epoch: 6 #\n",
      "Example: 49984, loss: 0.002\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.17%\n",
      "# Train Epoch: 7 #\n",
      "Example: 49984, loss: 0.000\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.23%\n",
      "# Train Epoch: 8 #\n",
      "Example: 49984, loss: 0.002\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.29%\n",
      "# Train Epoch: 9 #\n",
      "Example: 49984, loss: 0.016\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.34%\n",
      "# Train Epoch: 10 #\n",
      "Example: 49984, loss: 0.001\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.40%\n",
      "# Train Epoch: 11 #\n",
      "Example: 49984, loss: 0.000\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.45%\n",
      "# Train Epoch: 12 #\n",
      "Example: 49984, loss: 0.000\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.49%\n",
      "# Train Epoch: 13 #\n",
      "Example: 49984, loss: 0.029\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.52%\n",
      "# Train Epoch: 14 #\n",
      "Example: 49984, loss: 0.004\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.55%\n",
      "\n",
      "End time Training: 2023-12-03 19:34:54.747332\n",
      "Training time: 40 min 30 sec \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_no_quantization.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_no_quantization(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_no_quantization.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")\n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ac6a91-dce7-44cf-85c4-4ceaa96237ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_no_quantization/Conv_0.syntxt\n",
      "Import ./model_no_quantization/Conv_1.syntxt\n",
      "Import ./model_no_quantization/Conv_2.syntxt\n",
      "Import ./model_no_quantization/Fc_0.syntxt\n",
      "Import ./model_no_quantization/Fc_1.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 13.491427 sec\n",
      "\n",
      "### Testing - Iteration 2/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 10.902649 sec\n",
      "\n",
      "### Testing - Iteration 3/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 10.955413 sec\n",
      "\n",
      "### Testing - Iteration 4/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 10.754414 sec\n",
      "\n",
      "### Testing - Iteration 5/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 11.236933 sec\n",
      "\n",
      "### Testing - Iteration 6/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 11.261077 sec\n",
      "\n",
      "### Testing - Iteration 7/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 12.084264 sec\n",
      "\n",
      "### Testing - Iteration 8/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 10.968513 sec\n",
      "\n",
      "### Testing - Iteration 9/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 10.642368 sec\n",
      "\n",
      "### Testing - Iteration 10/10 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 10.860791 sec\n",
      "\n",
      "Average Inference time over 10 iterations: 0 min 11.315785 sec\n"
     ]
    }
   ],
   "source": [
    "model_no_quantization.import_free_parameters(\"./model_no_quantization\", ignore_not_exists=True)\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_no_quantization.test()\n",
    "\n",
    "num_tests = 10\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_no_quantization\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_no_quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da86c0-dda9-40af-b243-f88c0fc23e02",
   "metadata": {},
   "source": [
    "## MNIST - 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a4c27e-7d8a-4286-b345-161b839a39bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Loading Model (8 bit quantization) ###\n",
      "'Sequence_1' Sequence(\n",
      "\t(0): 'Conv_3' Conv(Frame<float>)(nb_inputs=1, nb_outputs=6, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe308363b70>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=255))\n",
      "\t(1): 'Pool2d_2' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(2): 'Conv_4' Conv(Frame<float>)(nb_inputs=6, nb_outputs=16, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3083949f0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=255))\n",
      "\t(3): 'Pool2d_3' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(4): 'Conv_5' Conv(Frame<float>)(nb_inputs=16, nb_outputs=120, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3083957f0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=255))\n",
      "\t(5): 'Fc_2' Fc(Frame<float>)(nb_inputs=120, nb_outputs=84 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe308396170>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=255))\n",
      "\t(6): 'Fc_3' Fc(Frame<float>)(nb_inputs=84, nb_outputs=10 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Linear(clipping=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe308396a70>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=255))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model 8 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (8 bit quantization) ###\")\n",
    "model_quant_8bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(8)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(8)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(8)),\n",
    "])\n",
    "print(model_quant_8bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "240ca7c5-0007-4d2b-be2b-a03c335f6965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training ###\n",
      "Start time Training: 2023-12-03 19:36:43.009994\n",
      "\n",
      "# Train Epoch: 0 #\n",
      "Example: 49984, loss: 0.061\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.75%\n",
      "# Train Epoch: 1 #\n",
      "Example: 49984, loss: 0.044\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.85%\n",
      "# Train Epoch: 2 #\n",
      "Example: 49984, loss: 0.018\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.20%\n",
      "# Train Epoch: 3 #\n",
      "Example: 49984, loss: 0.017\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.31%\n",
      "# Train Epoch: 4 #\n",
      "Example: 49984, loss: 0.030\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.46%\n",
      "# Train Epoch: 5 #\n",
      "Example: 49984, loss: 0.040\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.57%\n",
      "# Train Epoch: 6 #\n",
      "Example: 49984, loss: 0.026\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.70%\n",
      "# Train Epoch: 7 #\n",
      "Example: 49984, loss: 0.025\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.76%\n",
      "# Train Epoch: 8 #\n",
      "Example: 49984, loss: 0.001\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.85%\n",
      "# Train Epoch: 9 #\n",
      "Example: 49984, loss: 0.028\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.90%\n",
      "# Train Epoch: 10 #\n",
      "Example: 49984, loss: 0.004\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.96%\n",
      "# Train Epoch: 11 #\n",
      "Example: 49984, loss: 0.029\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.01%\n",
      "# Train Epoch: 12 #\n",
      "Example: 49984, loss: 0.013\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.06%\n",
      "# Train Epoch: 13 #\n",
      "Example: 49984, loss: 0.004\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.09%\n",
      "# Train Epoch: 14 #\n",
      "Example: 49984, loss: 0.000\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.13%\n",
      "\n",
      "End time Training: 2023-12-03 20:20:38.847854\n",
      "Training time: 43 min 55 sec \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_8bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_8bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ed05d0-8345-4cbd-bbc7-8b2ca6afd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_8bit/Conv_3.syntxt\n",
      "Import ./model_quant_8bit/Conv_4.syntxt\n",
      "Import ./model_quant_8bit/Conv_5.syntxt\n",
      "Import ./model_quant_8bit/Fc_2.syntxt\n",
      "Import ./model_quant_8bit/Fc_3.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 13.867264 sec\n",
      "\n",
      "### Testing - Iteration 2/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 12.157445 sec\n",
      "\n",
      "### Testing - Iteration 3/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 12.810935 sec\n",
      "\n",
      "### Testing - Iteration 4/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 12.73464 sec\n",
      "\n",
      "### Testing - Iteration 5/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 12.863632 sec\n",
      "\n",
      "### Testing - Iteration 6/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 15.375964 sec\n",
      "\n",
      "### Testing - Iteration 7/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 12.346775 sec\n",
      "\n",
      "### Testing - Iteration 8/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 12.462492 sec\n",
      "\n",
      "### Testing - Iteration 9/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 12.78464 sec\n",
      "\n",
      "### Testing - Iteration 10/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 13.946452 sec\n",
      "\n",
      "Average Inference time over 10 iterations: 0 min 13.135024 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_8bit.import_free_parameters(\"./model_quant_8bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_8bit.test()\n",
    "\n",
    "num_tests = 10\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_8bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_8bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093bcd66-da90-4fae-8137-be61f9e905f1",
   "metadata": {},
   "source": [
    "## MNIST - 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d73c470-95f4-4e2e-b42a-d5c19868202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Loading Model (4 bit quantization) ###\n",
      "'Sequence_2' Sequence(\n",
      "\t(0): 'Conv_6' Conv(Frame<float>)(nb_inputs=1, nb_outputs=6, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081b0030>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=15))\n",
      "\t(1): 'Pool2d_4' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(2): 'Conv_7' Conv(Frame<float>)(nb_inputs=6, nb_outputs=16, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081b0cb0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=15))\n",
      "\t(3): 'Pool2d_5' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(4): 'Conv_8' Conv(Frame<float>)(nb_inputs=16, nb_outputs=120, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081b1ab0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=15))\n",
      "\t(5): 'Fc_4' Fc(Frame<float>)(nb_inputs=120, nb_outputs=84 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081b2570>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=15))\n",
      "\t(6): 'Fc_5' Fc(Frame<float>)(nb_inputs=84, nb_outputs=10 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Linear(clipping=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081b2ff0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=15))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model 4 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (4 bit quantization) ###\")\n",
    "model_quant_4bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(4)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(4)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(4)),\n",
    "])\n",
    "print(model_quant_4bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfff84bd-e5d6-4a77-8683-c8467da7350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training ###\n",
      "Start time Training: 2023-12-03 20:20:51.163511\n",
      "\n",
      "# Train Epoch: 0 #\n",
      "Example: 49984, loss: 0.038\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.27%\n",
      "# Train Epoch: 1 #\n",
      "Example: 49984, loss: 0.063\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.36%\n",
      "# Train Epoch: 2 #\n",
      "Example: 49984, loss: 0.017\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.53%\n",
      "# Train Epoch: 3 #\n",
      "Example: 49984, loss: 0.054\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.66%\n",
      "# Train Epoch: 4 #\n",
      "Example: 49984, loss: 0.002\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.65%\n",
      "# Train Epoch: 5 #\n",
      "Example: 49984, loss: 0.034\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.70%\n",
      "# Train Epoch: 6 #\n",
      "Example: 49984, loss: 0.013\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.79%\n",
      "# Train Epoch: 7 #\n",
      "Example: 49984, loss: 0.058\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.84%\n",
      "# Train Epoch: 8 #\n",
      "Example: 49984, loss: 0.043\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.92%\n",
      "# Train Epoch: 9 #\n",
      "Example: 49984, loss: 0.036\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.97%\n",
      "# Train Epoch: 10 #\n",
      "Example: 49984, loss: 0.005\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.04%\n",
      "# Train Epoch: 11 #\n",
      "Example: 49984, loss: 0.003\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.07%\n",
      "# Train Epoch: 12 #\n",
      "Example: 49984, loss: 0.006\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.13%\n",
      "# Train Epoch: 13 #\n",
      "Example: 49984, loss: 0.039\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.16%\n",
      "# Train Epoch: 14 #\n",
      "Example: 49984, loss: 0.008\n",
      "### Validation ###\n",
      "Test: 9984, success: 98.19%\n",
      "\n",
      "End time Training: 2023-12-03 21:05:52.937804\n",
      "Training time: 45 min 1 sec \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_4bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_4bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f265a197-45ac-479b-82e9-5f27ac7f5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_4bit/Conv_6.syntxt\n",
      "Import ./model_quant_4bit/Conv_7.syntxt\n",
      "Import ./model_quant_4bit/Conv_8.syntxt\n",
      "Import ./model_quant_4bit/Fc_4.syntxt\n",
      "Import ./model_quant_4bit/Fc_5.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 13.19207 sec\n",
      "\n",
      "### Testing - Iteration 2/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 11.582677 sec\n",
      "\n",
      "### Testing - Iteration 3/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 11.369207 sec\n",
      "\n",
      "### Testing - Iteration 4/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 11.56972 sec\n",
      "\n",
      "### Testing - Iteration 5/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 11.843204 sec\n",
      "\n",
      "### Testing - Iteration 6/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 13.457995 sec\n",
      "\n",
      "### Testing - Iteration 7/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 13.419852 sec\n",
      "\n",
      "### Testing - Iteration 8/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 11.871306 sec\n",
      "\n",
      "### Testing - Iteration 9/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 11.763163 sec\n",
      "\n",
      "### Testing - Iteration 10/10 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 11.954865 sec\n",
      "\n",
      "Average Inference time over 10 iterations: 0 min 12.202406 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_4bit.import_free_parameters(\"./model_quant_4bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_4bit.test()\n",
    "\n",
    "num_tests = 10\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_4bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_4bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1d461-65cb-4bd7-b82c-846a9ddf583b",
   "metadata": {},
   "source": [
    "## MNIST - 2 bit quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a79de8c-494c-4c02-9c8f-fea5e150362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Loading Model (2 bit quantization) ###\n",
      "'Sequence_3' Sequence(\n",
      "\t(0): 'Conv_9' Conv(Frame<float>)(nb_inputs=1, nb_outputs=6, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081dc630>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=3))\n",
      "\t(1): 'Pool2d_6' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(2): 'Conv_10' Conv(Frame<float>)(nb_inputs=6, nb_outputs=16, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081dd330>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=3))\n",
      "\t(3): 'Pool2d_7' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(4): 'Conv_11' Conv(Frame<float>)(nb_inputs=16, nb_outputs=120, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081de2b0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=3))\n",
      "\t(5): 'Fc_6' Fc(Frame<float>)(nb_inputs=120, nb_outputs=84 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081ded30>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=3))\n",
      "\t(6): 'Fc_7' Fc(Frame<float>)(nb_inputs=84, nb_outputs=10 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Linear(clipping=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081df7b0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=3))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model 2 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (2 bit quantization) ###\")\n",
    "model_quant_2bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(2)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(2)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(2)),\n",
    "])\n",
    "print(model_quant_2bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55825ecf-ab9a-463d-b32f-d9f53b18e4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training ###\n",
      "Start time Training: 2023-12-04 00:01:14.710996\n",
      "\n",
      "# Train Epoch: 0 #\n",
      "Example: 49984, loss: 0.098\n",
      "### Validation ###\n",
      "Test: 9984, success: 95.38%\n",
      "# Train Epoch: 1 #\n",
      "Example: 49984, loss: 0.111\n",
      "### Validation ###\n",
      "Test: 9984, success: 95.61%\n",
      "# Train Epoch: 2 #\n",
      "Example: 49984, loss: 0.040\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.02%\n",
      "# Train Epoch: 3 #\n",
      "Example: 49984, loss: 0.069\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.32%\n",
      "# Train Epoch: 4 #\n",
      "Example: 49984, loss: 0.041\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.56%\n",
      "# Train Epoch: 5 #\n",
      "Example: 49984, loss: 0.064\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.70%\n",
      "# Train Epoch: 6 #\n",
      "Example: 49984, loss: 0.039\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.80%\n",
      "# Train Epoch: 7 #\n",
      "Example: 49984, loss: 0.004\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.92%\n",
      "# Train Epoch: 8 #\n",
      "Example: 49984, loss: 0.057\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.01%\n",
      "# Train Epoch: 9 #\n",
      "Example: 49984, loss: 0.001\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.11%\n",
      "# Train Epoch: 10 #\n",
      "Example: 49984, loss: 0.010\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.17%\n",
      "# Train Epoch: 11 #\n",
      "Example: 49984, loss: 0.017\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.24%\n",
      "# Train Epoch: 12 #\n",
      "Example: 49984, loss: 0.010\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.31%\n",
      "# Train Epoch: 13 #\n",
      "Example: 49984, loss: 0.053\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.37%\n",
      "# Train Epoch: 14 #\n",
      "Example: 49984, loss: 0.007\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.41%\n",
      "\n",
      "End time Training: 2023-12-04 00:48:14.490689\n",
      "Training time: 46 min 59 sec \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_2bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_2bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef29626-9013-4024-9162-c03fe9727676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_2bit/Conv_9.syntxt\n",
      "Import ./model_quant_2bit/Conv_10.syntxt\n",
      "Import ./model_quant_2bit/Conv_11.syntxt\n",
      "Import ./model_quant_2bit/Fc_6.syntxt\n",
      "Import ./model_quant_2bit/Fc_7.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 15.145115 sec\n",
      "\n",
      "### Testing - Iteration 2/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 13.298702 sec\n",
      "\n",
      "### Testing - Iteration 3/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 12.089503 sec\n",
      "\n",
      "### Testing - Iteration 4/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 11.342185 sec\n",
      "\n",
      "### Testing - Iteration 5/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 12.491538 sec\n",
      "\n",
      "### Testing - Iteration 6/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 11.272655 sec\n",
      "\n",
      "### Testing - Iteration 7/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 11.813902 sec\n",
      "\n",
      "### Testing - Iteration 8/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 11.889186 sec\n",
      "\n",
      "### Testing - Iteration 9/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 11.772946 sec\n",
      "\n",
      "### Testing - Iteration 10/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 12.498027 sec\n",
      "\n",
      "Average Inference time over 10 iterations: 0 min 12.361376 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_2bit.import_free_parameters(\"./model_quant_2bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_2bit.test()\n",
    "\n",
    "num_tests = 10\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "#target.log_confusion_matrix(\"model_quant_2bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_2bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250185e5-46d3-4cf2-baca-3ba1971fb45d",
   "metadata": {},
   "source": [
    "## MNIST - 1 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8c6a74-9346-4b24-96ef-e2622b80da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Loading Model (1 bit quantization) ###\n",
      "'Sequence_4' Sequence(\n",
      "\t(0): 'Conv_12' Conv(Frame<float>)(nb_inputs=1, nb_outputs=6, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081f0d70>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=1))\n",
      "\t(1): 'Pool2d_8' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(2): 'Conv_13' Conv(Frame<float>)(nb_inputs=6, nb_outputs=16, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081f1b70>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=1))\n",
      "\t(3): 'Pool2d_9' Pool2d(Frame<float>)(pool_dims=[2, 2], stride_dims=[2, 2], pooling=Pooling.Average | activation=None)\n",
      "\t(4): 'Conv_14' Conv(Frame<float>)(nb_inputs=16, nb_outputs=120, kernel_dims=[5, 5], sub_sample_dims=[1, 1], stride_dims=[1, 1], padding_dims=[0, 0], dilation_dims=[1, 1] | back_propagate=True, no_bias=True, outputs_remap=, weights_export_flip=False, weights_export_format=OCHW, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081f28f0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=1))\n",
      "\t(5): 'Fc_8' Fc(Frame<float>)(nb_inputs=120, nb_outputs=84 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Rectifier(clipping=0.0, leak_slope=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081f32f0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=1))\n",
      "\t(6): 'Fc_9' Fc(Frame<float>)(nb_inputs=84, nb_outputs=10 | back_propagate=True, drop_connect=1.0, no_bias=True, normalize=False, outputs_remap=, weights_export_format=OC, activation=Linear(clipping=0.0, quantizer=None, scaling=<N2D2.Scaling object at 0x7fe3081f3db0>), weights_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), bias_solver=Adam(beta1=0.9, beta2=0.999, clamping=, epsilon=1e-08, learning_rate=0.001), weights_filler=Normal(mean=0.0, std_dev=0.05), bias_filler=Normal(mean=0.0, std_dev=0.05), quantizer=SATCell(apply_quantization=True, apply_scaling=True, quant_mode=Default, range=1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model 1 bit quantization\n",
    "\n",
    "print(\"\\n### Loading Model (1 bit quantization) ###\")\n",
    "model_quant_1bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(1)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(1)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(1)),\n",
    "])\n",
    "print(model_quant_1bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd8ca72-4a31-4a7e-812f-e3824cf75482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training ###\n",
      "Start time Training: 2023-12-04 00:48:26.793640\n",
      "\n",
      "# Train Epoch: 0 #\n",
      "Example: 49984, loss: 0.027\n",
      "### Validation ###\n",
      "Test: 9984, success: 94.52%\n",
      "# Train Epoch: 1 #\n",
      "Example: 49984, loss: 0.144\n",
      "### Validation ###\n",
      "Test: 9984, success: 95.20%\n",
      "# Train Epoch: 2 #\n",
      "Example: 49984, loss: 0.056\n",
      "### Validation ###\n",
      "Test: 9984, success: 95.77%\n",
      "# Train Epoch: 3 #\n",
      "Example: 49984, loss: 0.084\n",
      "### Validation ###\n",
      "Test: 9984, success: 95.98%\n",
      "# Train Epoch: 4 #\n",
      "Example: 49984, loss: 0.048\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.24%\n",
      "# Train Epoch: 5 #\n",
      "Example: 49984, loss: 0.052\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.43%\n",
      "# Train Epoch: 6 #\n",
      "Example: 49984, loss: 0.015\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.63%\n",
      "# Train Epoch: 7 #\n",
      "Example: 49984, loss: 0.064\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.74%\n",
      "# Train Epoch: 8 #\n",
      "Example: 49984, loss: 0.032\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.85%\n",
      "# Train Epoch: 9 #\n",
      "Example: 49984, loss: 0.071\n",
      "### Validation ###\n",
      "Test: 9984, success: 96.95%\n",
      "# Train Epoch: 10 #\n",
      "Example: 49984, loss: 0.011\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.04%\n",
      "# Train Epoch: 11 #\n",
      "Example: 49984, loss: 0.020\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.11%\n",
      "# Train Epoch: 12 #\n",
      "Example: 49984, loss: 0.018\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.14%\n",
      "# Train Epoch: 13 #\n",
      "Example: 49984, loss: 0.046\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.21%\n",
      "# Train Epoch: 14 #\n",
      "Example: 49984, loss: 0.017\n",
      "### Validation ###\n",
      "Test: 9984, success: 97.23%\n",
      "\n",
      "End time Training: 2023-12-04 01:35:32.901690\n",
      "Training time: 47 min 6 sec \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_1bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_1bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a63efa62-a3f3-4825-8217-20bed11bd13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_1bit/Conv_12.syntxt\n",
      "Import ./model_quant_1bit/Conv_13.syntxt\n",
      "Import ./model_quant_1bit/Conv_14.syntxt\n",
      "Import ./model_quant_1bit/Fc_8.syntxt\n",
      "Import ./model_quant_1bit/Fc_9.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 10.075939 sec\n",
      "\n",
      "### Testing - Iteration 2/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 10.685206 sec\n",
      "\n",
      "### Testing - Iteration 3/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 13.26697 sec\n",
      "\n",
      "### Testing - Iteration 4/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 10.882389 sec\n",
      "\n",
      "### Testing - Iteration 5/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 11.311733 sec\n",
      "\n",
      "### Testing - Iteration 6/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 12.203432 sec\n",
      "\n",
      "### Testing - Iteration 7/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 11.226479 sec\n",
      "\n",
      "### Testing - Iteration 8/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 11.307347 sec\n",
      "\n",
      "### Testing - Iteration 9/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 14.681985 sec\n",
      "\n",
      "### Testing - Iteration 10/10 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 15.179061 sec\n",
      "\n",
      "Average Inference time over 10 iterations: 0 min 12.082054 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_1bit.import_free_parameters(\"./model_quant_1bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_1bit.test()\n",
    "\n",
    "num_tests = 10\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "#target.log_confusion_matrix(\"model_quant_1bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_1bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67294419-61ff-4921-ab7f-12a6e970cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in model_quant_1bit.get_cells().values():\n",
    "     try:\n",
    "        weights = cell.get_weights()\n",
    "        print(weights)\n",
    "     except AttributeError as e:\n",
    "        print(f\"Attention: {cell} Error: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327842d6-54a7-4a09-ae9c-45d2e3683054",
   "metadata": {},
   "source": [
    "## Clean and rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0352e5f4-c8ff-460a-8fe7-b9319d173e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_rename_files(folder_path):\n",
    "    try:\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        # Delete files that do not contain \"quant\" in the name\n",
    "        for file_name in files:\n",
    "            if \"quant\" not in file_name:\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                os.remove(file_path)\n",
    "                \n",
    "        # Rename the remaining files by removing all occurrences of \"_quant\"\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if \"quant\" in file_name:\n",
    "                new_name = file_name.replace(\"_quant\", \"\")\n",
    "                old_path = os.path.join(folder_path, file_name)\n",
    "                new_path = os.path.join(folder_path, new_name)\n",
    "                os.rename(old_path, new_path)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636c230-9352-44d7-9a59-b3a6a74d1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_and_rename_files(\"./model_quant_8bit\")\n",
    "#clean_and_rename_files(\"./model_quant_4bit\")\n",
    "#clean_and_rename_files(\"./model_quant_2bit\")\n",
    "#clean_and_rename_files(\"./model_quant_1bit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
