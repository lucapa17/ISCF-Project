{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c0cbaa-e1f8-42de-bb65-e425966866de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import n2d2\n",
    "from n2d2.cells.nn import Fc, Conv, Pool2d\n",
    "import math\n",
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddbd15c-95e9-422a-b8c6-7734edcd2714",
   "metadata": {},
   "source": [
    "## MNIST - Final Table\n",
    "# 1st Architecure\n",
    "\n",
    "| Quantization Level | Accuracy | Training Time | Inference Time |\n",
    "| ------------------- | -------- | ------------- | -------------- |\n",
    "| No quantization     | 99.03%    | 40 min 30 sec    | 3.775001 sec     |\n",
    "| 8 bits              | 98.72%      | 43 min 55 sec   | 4.272405 sec     |\n",
    "| 4 bits              | 98.70%     | 45 min 1 sec    | 4.440299 sec    |\n",
    "| 2 bits              | 97.87%     | 46 min 59 sec    | 4.528385 sec   |\n",
    "| 1 bit               | 97.69%      | 47 min 6 sec    | 4.373531 sec    |\n",
    "\n",
    "# 2nd Architecure\n",
    "\n",
    "| Quantization Level | Accuracy | Training Time | Inference Time |\n",
    "| ------------------- | -------- | ------------- | -------------- |\n",
    "| No quantization     | 98.56%    | 46 min 17 sec    | 8.284389 sec     |\n",
    "| 8 bits              | 98.95%      | 49 min 9 sec    | 9.225595 sec     |\n",
    "| 4 bits              | 98.67%     | 49 min 43 sec    | 9.265473 sec    |\n",
    "| 2 bits              | 98.59%     | 49 min 22 secc    | 9.86159 sec    |\n",
    "| 1 bit               | 98.48%     | 48 min 12 sec     | 9.528501 sec    |\n",
    "\n",
    "# 3rd Architecure\n",
    "\n",
    "| Quantization Level | Accuracy | Training Time | Inference Time |\n",
    "| ------------------- | -------- | ------------- | -------------- |\n",
    "| No quantization     | 99.10%   | 83 min 50 sec     | 13.732805 sec     |\n",
    "| 8 bits              | 98.80%     | 87 min 20 sec    | 12.498102 sec     |\n",
    "| 4 bits              | 99.13%     | 88 min 33 sec    | 12.643952 sec   |\n",
    "| 2 bits              | 98.45%     | 89 min 35 sec     | 12.630759 sec    |\n",
    "| 1 bit               | 98.63%     | 90 min 40 sec     | 14.084402 sec   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87761499-c633-4244-9b95-69577d3ba3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and processing MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46eeed77-fc3c-4d0c-94c7-e608985e6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for item in train_dataset:\n",
    "    image, label = item\n",
    "    data.append(image.numpy())\n",
    "    labels.append(label)\n",
    "\n",
    "for item in test_dataset:\n",
    "    image, label = item\n",
    "    data.append(image.numpy())\n",
    "    labels.append(label)\n",
    "\n",
    "db = n2d2.database.Numpy(random_partitioning=False)\n",
    "db.load(data, labels)\n",
    "db.partition_stimuli(5/7, 1/7, 1/7) # training: 50k, validation: 10k, test: 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8596af0-1d09-4b35-8289-4d684f66a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Create Provider ###\")\n",
    "batch_size = 64\n",
    "provider = n2d2.provider.DataProvider(db, [32, 32, 1], batch_size=batch_size)\n",
    "provider.add_transformation(n2d2.transform.Rescale(width=32, height=32))\n",
    "print(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40cb315-f700-4859-8190-60d2ab3b207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_conf = n2d2.ConfigSection(\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "\n",
    "def conv_conf():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "    \n",
    "def fc_conf1():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "def fc_conf2():\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Linear(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "    )\n",
    "    \n",
    "# Definition of layers for quantization\n",
    "\n",
    "def conv_quantization_conf(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def fc_quantization_conf1(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Rectifier(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )\n",
    "def fc_quantization_conf2(n_bits):\n",
    "    return n2d2.ConfigSection(\n",
    "        activation=n2d2.activation.Linear(),\n",
    "        no_bias=True,\n",
    "        weights_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        bias_solver=n2d2.solver.Adam(**solver_conf),\n",
    "        quantizer=n2d2.quantizer.SATCell(\n",
    "            apply_scaling=True,\n",
    "            apply_quantization=True,\n",
    "            range=2**n_bits-1,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcc8a0-1f8d-4c4f-ac93-46d95eb3b5ad",
   "metadata": {},
   "source": [
    "# 1st architecture\n",
    "\n",
    "## MNIST - No Quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc7acd-89e5-42d7-bc45-974ab185f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Loading Model (without quantization) ###\")\n",
    "model_no_quantization = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_conf()),\n",
    "    Fc(120, 84, **fc_conf1()),\n",
    "    Fc(84, 10, **fc_conf2()),\n",
    "])\n",
    "print(model_no_quantization)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99260150-64e5-4b98-9952-79feb20949a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_no_quantization.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_no_quantization(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_no_quantization.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")\n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ac6a91-dce7-44cf-85c4-4ceaa96237ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_no_quantization/Conv_0.syntxt\n",
      "Import ./model_no_quantization/Conv_1.syntxt\n",
      "Import ./model_no_quantization/Conv_2.syntxt\n",
      "Import ./model_no_quantization/Fc_0.syntxt\n",
      "Import ./model_no_quantization/Fc_1.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 3.703957 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 3.556125 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 3.820641 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 3.847445 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.03%\n",
      "Inference time: 0 min 3.946836 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 3.775001 sec\n"
     ]
    }
   ],
   "source": [
    "model_no_quantization.import_free_parameters(\"./model_no_quantization\", ignore_not_exists=True)\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_no_quantization.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_no_quantization\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_no_quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da86c0-dda9-40af-b243-f88c0fc23e02",
   "metadata": {},
   "source": [
    "## MNIST - 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4c27e-7d8a-4286-b345-161b839a39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (8 bit quantization) ###\")\n",
    "model_quant_8bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(8)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(8)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(8)),\n",
    "])\n",
    "print(model_quant_8bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ca7c5-0007-4d2b-be2b-a03c335f6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_8bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_8bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ed05d0-8345-4cbd-bbc7-8b2ca6afd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_8bit/Conv_3.syntxt\n",
      "Import ./model_quant_8bit/Conv_4.syntxt\n",
      "Import ./model_quant_8bit/Conv_5.syntxt\n",
      "Import ./model_quant_8bit/Fc_2.syntxt\n",
      "Import ./model_quant_8bit/Fc_3.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 4.324526 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 4.169316 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 4.341966 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 4.28754 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.72%\n",
      "Inference time: 0 min 4.238677 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 4.272405 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_8bit.import_free_parameters(\"./model_quant_8bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_8bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_8bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_8bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093bcd66-da90-4fae-8137-be61f9e905f1",
   "metadata": {},
   "source": [
    "## MNIST - 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73c470-95f4-4e2e-b42a-d5c19868202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (4 bit quantization) ###\")\n",
    "model_quant_4bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(4)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(4)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(4)),\n",
    "])\n",
    "print(model_quant_4bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff84bd-e5d6-4a77-8683-c8467da7350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_4bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_4bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f265a197-45ac-479b-82e9-5f27ac7f5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_4bit/Conv_6.syntxt\n",
      "Import ./model_quant_4bit/Conv_7.syntxt\n",
      "Import ./model_quant_4bit/Conv_8.syntxt\n",
      "Import ./model_quant_4bit/Fc_4.syntxt\n",
      "Import ./model_quant_4bit/Fc_5.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 4.556242 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 4.409259 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 4.489339 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 4.346393 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.70%\n",
      "Inference time: 0 min 4.40026 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 4.440299 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_4bit.import_free_parameters(\"./model_quant_4bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_4bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_4bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_4bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1d461-65cb-4bd7-b82c-846a9ddf583b",
   "metadata": {},
   "source": [
    "## MNIST - 2 bit quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79de8c-494c-4c02-9c8f-fea5e150362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (2 bit quantization) ###\")\n",
    "model_quant_2bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(2)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(2)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(2)),\n",
    "])\n",
    "print(model_quant_2bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55825ecf-ab9a-463d-b32f-d9f53b18e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_2bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_2bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eef29626-9013-4024-9162-c03fe9727676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_2bit/Conv_9.syntxt\n",
      "Import ./model_quant_2bit/Conv_10.syntxt\n",
      "Import ./model_quant_2bit/Conv_11.syntxt\n",
      "Import ./model_quant_2bit/Fc_6.syntxt\n",
      "Import ./model_quant_2bit/Fc_7.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 4.785989 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 4.439795 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 4.469972 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 4.404923 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.87%\n",
      "Inference time: 0 min 4.541248 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 4.528385 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_2bit.import_free_parameters(\"./model_quant_2bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_2bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_2bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_2bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250185e5-46d3-4cf2-baca-3ba1971fb45d",
   "metadata": {},
   "source": [
    "## MNIST - 1 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c6a74-9346-4b24-96ef-e2622b80da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 bit quantization\n",
    "\n",
    "print(\"\\n### Loading Model (1 bit quantization) ###\")\n",
    "model_quant_1bit = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 120, [5, 5], **conv_quantization_conf(1)),\n",
    "    Fc(120, 84, **fc_quantization_conf1(1)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(1)),\n",
    "])\n",
    "print(model_quant_1bit)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8ca72-4a31-4a7e-812f-e3824cf75482",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_1bit.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_1bit.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a63efa62-a3f3-4825-8217-20bed11bd13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_1bit/Conv_12.syntxt\n",
      "Import ./model_quant_1bit/Conv_13.syntxt\n",
      "Import ./model_quant_1bit/Conv_14.syntxt\n",
      "Import ./model_quant_1bit/Fc_8.syntxt\n",
      "Import ./model_quant_1bit/Fc_9.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 4.602498 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 4.231095 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 4.37966 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 4.289869 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 97.69%\n",
      "Inference time: 0 min 4.364535 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 4.373531 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_1bit.import_free_parameters(\"./model_quant_1bit\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_1bit.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_1bit\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_1bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130345d4-3e66-4c48-b52e-9734710267df",
   "metadata": {},
   "source": [
    "# 2nd architecture (deeper)\n",
    "\n",
    "## MNIST - No Quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef9de0-5b6e-4f1f-bdf6-e22ba45664f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Loading Model (without quantization) ###\")\n",
    "model_no_quantization_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_conf()),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_conf()),\n",
    "    Conv(24, 120, [5, 5], **conv_conf()), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_conf1()),\n",
    "    Fc(84, 10, **fc_conf2()),\n",
    "])\n",
    "print(model_no_quantization_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab8133-551f-41fb-ae0a-02301d7dbd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_no_quantization_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_no_quantization_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_no_quantization_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")\n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec5fe17-0cf9-4efd-9b69-56eadb66127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_no_quantization_deeper_2nd/Conv_0.syntxt\n",
      "Import ./model_no_quantization_deeper_2nd/Conv_1.syntxt\n",
      "Import ./model_no_quantization_deeper_2nd/Conv_2.syntxt\n",
      "Import ./model_no_quantization_deeper_2nd/Conv_3.syntxt\n",
      "Import ./model_no_quantization_deeper_2nd/Fc_0.syntxt\n",
      "Import ./model_no_quantization_deeper_2nd/Fc_1.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.56%\n",
      "Inference time: 0 min 7.409847 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.56%\n",
      "Inference time: 0 min 7.773251 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.56%\n",
      "Inference time: 0 min 8.254102 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.56%\n",
      "Inference time: 0 min 8.980359 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.56%\n",
      "Inference time: 0 min 9.004386 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 8.284389 sec\n"
     ]
    }
   ],
   "source": [
    "model_no_quantization_deeper_2nd.import_free_parameters(\"./model_no_quantization_deeper_2nd\", ignore_not_exists=True)\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_no_quantization_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_no_quantization_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_no_quantization_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b35fd-780e-4ed1-b395-bbddfe8b1667",
   "metadata": {},
   "source": [
    "## MNIST - 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2d114-f4af-43e9-87ac-50b7b162d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (8 bit quantization) ###\")\n",
    "model_quant_8bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(8)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(8)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(8)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(8)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(8)),\n",
    "])\n",
    "print(model_quant_8bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26340094-882d-4354-97e2-17133e4c05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_8bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_8bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_8bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e472348a-116c-42cd-83b5-61f2ea3ff7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_8bit_deeper_2nd/Conv_4.syntxt\n",
      "Import ./model_quant_8bit_deeper_2nd/Conv_5.syntxt\n",
      "Import ./model_quant_8bit_deeper_2nd/Conv_6.syntxt\n",
      "Import ./model_quant_8bit_deeper_2nd/Conv_7.syntxt\n",
      "Import ./model_quant_8bit_deeper_2nd/Fc_2.syntxt\n",
      "Import ./model_quant_8bit_deeper_2nd/Fc_3.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.95%\n",
      "Inference time: 0 min 9.628103 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.95%\n",
      "Inference time: 0 min 9.336132 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.95%\n",
      "Inference time: 0 min 9.071231 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.95%\n",
      "Inference time: 0 min 9.081182 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.95%\n",
      "Inference time: 0 min 9.011325 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 9.225595 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_8bit_deeper_2nd.import_free_parameters(\"./model_quant_8bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_8bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_8bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_8bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129cb872-66c6-4216-bae5-ae9d70efae3c",
   "metadata": {},
   "source": [
    "## MNIST - 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72900078-a981-4ace-8171-0c27268d07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (4 bit quantization) ###\")\n",
    "model_quant_4bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(4)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(4)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(4)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(4)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(4)),\n",
    "])\n",
    "print(model_quant_4bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652e478-a0b4-4137-af76-d79ae298637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_4bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_4bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_4bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b16aec-c035-402b-94e4-d35c92a4db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_4bit_deeper_2nd/Conv_8.syntxt\n",
      "Import ./model_quant_4bit_deeper_2nd/Conv_9.syntxt\n",
      "Import ./model_quant_4bit_deeper_2nd/Conv_10.syntxt\n",
      "Import ./model_quant_4bit_deeper_2nd/Conv_11.syntxt\n",
      "Import ./model_quant_4bit_deeper_2nd/Fc_4.syntxt\n",
      "Import ./model_quant_4bit_deeper_2nd/Fc_5.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.67%\n",
      "Inference time: 0 min 9.590931 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.67%\n",
      "Inference time: 0 min 9.321509 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.67%\n",
      "Inference time: 0 min 9.062389 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.67%\n",
      "Inference time: 0 min 9.149059 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.67%\n",
      "Inference time: 0 min 9.203477 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 9.265473 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_4bit_deeper_2nd.import_free_parameters(\"./model_quant_4bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_4bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_4bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_4bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c26ff-e2e1-4a96-936b-ee433eb43465",
   "metadata": {},
   "source": [
    "## MNIST - 2 bit quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730dcaad-f534-44c3-aaa4-62ae0f4a19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (2 bit quantization) ###\")\n",
    "model_quant_2bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(2)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(2)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(2)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(2)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(2)),\n",
    "])\n",
    "print(model_quant_2bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc41682-ad00-4be4-a975-10fd6871263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_2bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_2bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_2bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03395fb9-a3b2-44fd-861d-428146d5eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_2bit_deeper_2nd/Conv_12.syntxt\n",
      "Import ./model_quant_2bit_deeper_2nd/Conv_13.syntxt\n",
      "Import ./model_quant_2bit_deeper_2nd/Conv_14.syntxt\n",
      "Import ./model_quant_2bit_deeper_2nd/Conv_15.syntxt\n",
      "Import ./model_quant_2bit_deeper_2nd/Fc_6.syntxt\n",
      "Import ./model_quant_2bit_deeper_2nd/Fc_7.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.59%\n",
      "Inference time: 0 min 10.59636 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.59%\n",
      "Inference time: 0 min 9.841643 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.59%\n",
      "Inference time: 0 min 9.617916 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.59%\n",
      "Inference time: 0 min 9.645591 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.59%\n",
      "Inference time: 0 min 9.60644 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 9.86159 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_2bit_deeper_2nd.import_free_parameters(\"./model_quant_2bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_2bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_2bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_2bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615e4fd-a779-4ebf-99c4-ebf406884163",
   "metadata": {},
   "source": [
    "## MNIST - 1 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd6eb0-5459-422b-8faa-9ed6e0042bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 bit quantization\n",
    "\n",
    "print(\"\\n### Loading Model (1 bit quantization) ###\")\n",
    "model_quant_1bit_deeper_2nd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(1)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 24, [5, 5], **conv_quantization_conf(1)),\n",
    "    Conv(24, 120, [5, 5], **conv_quantization_conf(1)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(120, 84, **fc_quantization_conf1(1)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(1)),\n",
    "])\n",
    "print(model_quant_1bit_deeper_2nd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517190f-d02a-46cc-b973-11ebb11d9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_1bit_deeper_2nd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_1bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_1bit_deeper_2nd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b26dee0-0fc3-4539-b8b6-b86c01285988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_1bit_deeper_2nd/Conv_16.syntxt\n",
      "Import ./model_quant_1bit_deeper_2nd/Conv_17.syntxt\n",
      "Import ./model_quant_1bit_deeper_2nd/Conv_18.syntxt\n",
      "Import ./model_quant_1bit_deeper_2nd/Conv_19.syntxt\n",
      "Import ./model_quant_1bit_deeper_2nd/Fc_8.syntxt\n",
      "Import ./model_quant_1bit_deeper_2nd/Fc_9.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.48%\n",
      "Inference time: 0 min 9.694403 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.48%\n",
      "Inference time: 0 min 9.422634 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.48%\n",
      "Inference time: 0 min 9.478879 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.48%\n",
      "Inference time: 0 min 9.576549 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.48%\n",
      "Inference time: 0 min 9.470038 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 9.528501 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_1bit_deeper_2nd.import_free_parameters(\"./model_quant_1bit_deeper_2nd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_1bit_deeper_2nd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit_deeper_2nd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_1bit_deeper_2nd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_1bit_deeper_2nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd4b525-6402-4e57-a8f0-e38789d6d6b7",
   "metadata": {},
   "source": [
    "# 3rd architecture (deeper)\n",
    "\n",
    "## MNIST - No Quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ede6d7-09f4-4ff5-add8-b33ba6a9f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Loading Model (without quantization) ###\")\n",
    "model_no_quantization_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_conf()),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_conf()),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_conf()),\n",
    "    Conv(32, 150, [5, 5], **conv_conf()), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_conf1()), # New Fc Layer\n",
    "    Fc(120, 84, **fc_conf1()),\n",
    "    Fc(84, 10, **fc_conf2()),\n",
    "])\n",
    "print(model_no_quantization_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c8d67-376a-422a-9783-4737049d4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_no_quantization_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_no_quantization_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_no_quantization_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")\n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c44aa2-0df1-4fde-8f53-7840a7b1bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_no_quantization_deeper_3rd/Conv_0.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Pool2d_0.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Conv_1.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Conv_2.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Conv_3.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Pool2d_1.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Fc_0.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Fc_1.syntxt\n",
      "Import ./model_no_quantization_deeper_3rd/Fc_2.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.10%\n",
      "Inference time: 0 min 13.582409 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.10%\n",
      "Inference time: 0 min 14.245616 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.10%\n",
      "Inference time: 0 min 13.351474 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.10%\n",
      "Inference time: 0 min 13.636946 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.10%\n",
      "Inference time: 0 min 13.847581 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 13.732805 sec\n"
     ]
    }
   ],
   "source": [
    "model_no_quantization_deeper_3rd.import_free_parameters(\"./model_no_quantization_deeper_3rd\", ignore_not_exists=True)\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_no_quantization_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_no_quantization_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_no_quantization_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_no_quantization_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b42ef68-1fdd-4aa1-a28f-81b1fe4bf95c",
   "metadata": {},
   "source": [
    "## MNIST - 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cc419-9d29-49f2-b8f7-5dd18a2ca8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (8 bit quantization) ###\")\n",
    "model_quant_8bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(8)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(8)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(8)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(8)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(8)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(8)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(8)),\n",
    "])\n",
    "print(model_quant_8bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe00e1-1265-4db5-b707-f15f5f53ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_8bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_8bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_8bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7734c45-f03d-4d16-9d81-d4c5e35cc4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_8bit_deeper_3rd/Conv_4.syntxt\n",
      "Import ./model_quant_8bit_deeper_3rd/Conv_5.syntxt\n",
      "Import ./model_quant_8bit_deeper_3rd/Conv_6.syntxt\n",
      "Import ./model_quant_8bit_deeper_3rd/Conv_7.syntxt\n",
      "Import ./model_quant_8bit_deeper_3rd/Fc_3.syntxt\n",
      "Import ./model_quant_8bit_deeper_3rd/Fc_4.syntxt\n",
      "Import ./model_quant_8bit_deeper_3rd/Fc_5.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.80%\n",
      "Inference time: 0 min 12.296041 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.80%\n",
      "Inference time: 0 min 12.503862 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.80%\n",
      "Inference time: 0 min 12.263672 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.80%\n",
      "Inference time: 0 min 12.712446 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.80%\n",
      "Inference time: 0 min 12.714488 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 12.498102 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_8bit_deeper_3rd.import_free_parameters(\"./model_quant_8bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_8bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_8bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_8bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_8bit_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4e536-4766-49ea-9028-9f5dc59e7e6e",
   "metadata": {},
   "source": [
    "## MNIST - 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220db9a-c6ed-4cd4-bcfd-a7090a5e1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (4 bit quantization) ###\")\n",
    "model_quant_4bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(4)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(4)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(4)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(4)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(4)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(4)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(4)),\n",
    "])\n",
    "print(model_quant_4bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65d6c4-23ce-4698-9c4b-ff7112fefb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_4bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_4bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_4bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c162b76-7aa4-45a4-8137-6fa54923015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_4bit_deeper_3rd/Conv_8.syntxt\n",
      "Import ./model_quant_4bit_deeper_3rd/Conv_9.syntxt\n",
      "Import ./model_quant_4bit_deeper_3rd/Conv_10.syntxt\n",
      "Import ./model_quant_4bit_deeper_3rd/Conv_11.syntxt\n",
      "Import ./model_quant_4bit_deeper_3rd/Fc_6.syntxt\n",
      "Import ./model_quant_4bit_deeper_3rd/Fc_7.syntxt\n",
      "Import ./model_quant_4bit_deeper_3rd/Fc_8.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.13%\n",
      "Inference time: 0 min 13.259955 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.13%\n",
      "Inference time: 0 min 12.417419 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.13%\n",
      "Inference time: 0 min 12.508533 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.13%\n",
      "Inference time: 0 min 12.235592 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 99.13%\n",
      "Inference time: 0 min 12.798259 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 12.643952 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_4bit_deeper_3rd.import_free_parameters(\"./model_quant_4bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_4bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_4bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_4bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_4bit_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55714ac3-838a-48d6-a08b-adfdd439fb61",
   "metadata": {},
   "source": [
    "## MNIST - 2 bit quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d5947-f628-4dac-a8df-39ec19965a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 bit quantization \n",
    "\n",
    "print(\"\\n### Loading Model (2 bit quantization) ###\")\n",
    "model_quant_2bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(2)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(2)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(2)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(2)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(2)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(2)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(2)),\n",
    "])\n",
    "print(model_quant_2bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1ecf9-062d-445e-91be-0f620740d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_2bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_2bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_2bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")        \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffc4618-ffc6-4293-a217-9cb10afafed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_2bit_deeper_3rd/Conv_12.syntxt\n",
      "Import ./model_quant_2bit_deeper_3rd/Conv_13.syntxt\n",
      "Import ./model_quant_2bit_deeper_3rd/Conv_14.syntxt\n",
      "Import ./model_quant_2bit_deeper_3rd/Conv_15.syntxt\n",
      "Import ./model_quant_2bit_deeper_3rd/Fc_9.syntxt\n",
      "Import ./model_quant_2bit_deeper_3rd/Fc_10.syntxt\n",
      "Import ./model_quant_2bit_deeper_3rd/Fc_11.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.45%\n",
      "Inference time: 0 min 12.733251 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.45%\n",
      "Inference time: 0 min 12.79451 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.45%\n",
      "Inference time: 0 min 12.728143 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.45%\n",
      "Inference time: 0 min 12.363416 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.45%\n",
      "Inference time: 0 min 12.534476 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 12.630759 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_2bit_deeper_3rd.import_free_parameters(\"./model_quant_2bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_2bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_2bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_2bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_2bit_deeper_3rd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0183896-0085-4692-ae56-662d02610f47",
   "metadata": {},
   "source": [
    "## MNIST - 1 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e139d98-bec2-45dc-bc1a-65dd7fee7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 bit quantization\n",
    "\n",
    "print(\"\\n### Loading Model (1 bit quantization) ###\")\n",
    "model_quant_1bit_deeper_3rd = n2d2.cells.Sequence([\n",
    "    Conv(1, 6, kernel_dims=[5, 5], **conv_quantization_conf(1)),\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(6, 16, [5, 5], **conv_quantization_conf(1)),\n",
    "    #Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Conv(16, 32, [5, 5], **conv_quantization_conf(1)),\n",
    "    Conv(32, 150, [5, 5], **conv_quantization_conf(1)), # New Conv Layer\n",
    "    Pool2d(pool_dims=[2, 2], stride_dims=[2, 2], pooling=\"Average\"),\n",
    "    Fc(150, 120, **fc_quantization_conf1(1)), # New Fc Layer\n",
    "    Fc(120, 84, **fc_quantization_conf1(1)),\n",
    "    Fc(84, 10, **fc_quantization_conf2(1)),\n",
    "])\n",
    "print(model_quant_1bit_deeper_3rd)\n",
    "softmax = n2d2.cells.Softmax(with_loss=True)\n",
    "target = n2d2.target.Score(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b18bf9-ede4-4a8f-a97c-267ed592d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 15\n",
    "target = n2d2.target.Score(provider)\n",
    "\n",
    "print(\"\\n### Training ###\")\n",
    "\n",
    "start_training_time = datetime.datetime.now()\n",
    "print(\"Start time Training: \" + str(start_training_time))\n",
    "for epoch in range(nb_epochs):\n",
    "    provider.set_partition(\"Learn\")\n",
    "    model_quant_1bit_deeper_3rd.learn()\n",
    "    print(\"\\n# Train Epoch: \" + str(epoch) + \" #\")\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Learn')/batch_size)):\n",
    "        x = provider.read_random_batch()\n",
    "        x = model_quant_1bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        x.back_propagate()\n",
    "        x.update()\n",
    "        print(\"Example: \" + str(i * batch_size) + \", loss: \"+ \"{0:.3f}\".format(x[0]), end='\\r')\n",
    "        \n",
    "    print(\"\\n### Validation ###\")\n",
    "    target.clear_success()\n",
    "    provider.set_partition('Validation')\n",
    "    model_quant_1bit_deeper_3rd.test()\n",
    "    for i in range(math.ceil(db.get_nb_stimuli('Validation') / batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "        print(\"Test: \" + str(i * batch_size) + \", success: \"+ \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "\n",
    "print(\"\\n\")       \n",
    "end_training_time = datetime.datetime.now()\n",
    "print(\"End time Training: \" + str(end_training_time))\n",
    "training_time = end_training_time - start_training_time\n",
    "minutes, seconds = divmod(training_time.total_seconds(), 60)\n",
    "print(\"Training time: \" + str(int(minutes)) + \" min \" + str(int(seconds)) + \" sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2002488c-5188-4839-9d42-e4e92107c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ./model_quant_1bit_deeper_3rd/Conv_16.syntxt\n",
      "Import ./model_quant_1bit_deeper_3rd/Conv_17.syntxt\n",
      "Import ./model_quant_1bit_deeper_3rd/Conv_18.syntxt\n",
      "Import ./model_quant_1bit_deeper_3rd/Conv_19.syntxt\n",
      "Import ./model_quant_1bit_deeper_3rd/Fc_12.syntxt\n",
      "Import ./model_quant_1bit_deeper_3rd/Fc_13.syntxt\n",
      "Import ./model_quant_1bit_deeper_3rd/Fc_14.syntxt\n",
      "\n",
      "### Testing ###\n",
      "\n",
      "### Testing - Iteration 1/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.63%\n",
      "Inference time: 0 min 12.777981 sec\n",
      "\n",
      "### Testing - Iteration 2/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.63%\n",
      "Inference time: 0 min 12.621042 sec\n",
      "\n",
      "### Testing - Iteration 3/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.63%\n",
      "Inference time: 0 min 16.022401 sec\n",
      "\n",
      "### Testing - Iteration 4/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.63%\n",
      "Inference time: 0 min 15.299848 sec\n",
      "\n",
      "### Testing - Iteration 5/5 ###\n",
      "\n",
      "Example: 9984, test success: 98.63%\n",
      "Inference time: 0 min 13.700739 sec\n",
      "\n",
      "Average Inference time over 5 iterations: 0 min 14.084402 sec\n"
     ]
    }
   ],
   "source": [
    "model_quant_1bit_deeper_3rd.import_free_parameters(\"./model_quant_1bit_deeper_3rd\", ignore_not_exists=True)\n",
    "\n",
    "provider.set_partition('Test')\n",
    "target = n2d2.target.Score(provider)\n",
    "print(\"\\n### Testing ###\")\n",
    "\n",
    "model_quant_1bit_deeper_3rd.test()\n",
    "\n",
    "num_tests = 5\n",
    "total_inference_time = datetime.timedelta()\n",
    "\n",
    "for test_iteration in range(num_tests):\n",
    "    print(f\"\\n### Testing - Iteration {test_iteration + 1}/{num_tests} ###\\n\")\n",
    "    start_testing_time = datetime.datetime.now()\n",
    "    for i in range(math.ceil(provider.get_database().get_nb_stimuli('Test')/batch_size)):\n",
    "        batch_idx = i*batch_size\n",
    "    \n",
    "        x = provider.read_batch(batch_idx)\n",
    "        x = model_quant_1bit_deeper_3rd(x)\n",
    "        x = softmax(x)\n",
    "        x = target(x)\n",
    "    \n",
    "        print(\"Example: \" + str(i * batch_size) + \", test success: \"\n",
    "              + \"{0:.2f}\".format(100 * target.get_average_success()) + \"%\", end='\\r')\n",
    "    \n",
    "    end_testing_time = datetime.datetime.now()\n",
    "    inference_time = end_testing_time - start_testing_time\n",
    "    total_inference_time += inference_time\n",
    "    minutes, seconds = divmod(inference_time.total_seconds(), 60)\n",
    "    print(\"\\nInference time: \" + str(int(minutes)) + \" min \" + str(seconds) + \" sec\")\n",
    "\n",
    "average_inference_time = total_inference_time / num_tests\n",
    "avg_minutes, avg_seconds = divmod(average_inference_time.total_seconds(), 60)\n",
    "print(\"\\nAverage Inference time over {} iterations: {} min {} sec\".format(num_tests, int(avg_minutes), avg_seconds))\n",
    "\n",
    "# save a confusion matrix\n",
    "target.log_confusion_matrix(\"model_quant_1bit_deeper_3rd\")\n",
    "# Exporting weights #\n",
    "#x.get_deepnet().export_network_free_parameters(\"./model_quant_1bit_deeper_3rd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
